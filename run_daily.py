"""
Moneyball Dojo - Daily Orchestrator v3 (å…¨å¸‚å ´å¯¾å¿œ)
====================================================
æ¯æ—¥ã“ã‚Œã‚’1å›å®Ÿè¡Œã™ã‚‹ã ã‘ã§:
1. æœ¬æ—¥ã®è©¦åˆãƒ‡ãƒ¼ã‚¿ã‚’MLB Stats APIã‹ã‚‰å–å¾—
2. ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ + ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¹ã‚¿ãƒƒãƒ„ã§ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
3. å…¨6ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬:
   - Moneyline (å‹æ•—)
   - Over/Under (åˆè¨ˆå¾—ç‚¹)
   - Run Line (-1.5ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰)
   - First 5 Innings (å‰åŠ5å›å‹æ•—)
   - Pitcher K Props (å…ˆç™ºæŠ•æ‰‹ã®å¥ªä¸‰æŒ¯æ•°)
   - Batter Props (æ‰“è€…ã®ãƒ’ãƒƒãƒˆ/HRæ•°)
4. ã‚¨ãƒƒã‚¸ï¼ˆãƒ¢ãƒ‡ãƒ«ç¢ºç‡ vs ãƒãƒ¼ã‚±ãƒƒãƒˆã‚ªãƒƒã‚ºï¼‰ã‚’è¨ˆç®—
5. Substackç”¨ã®è‹±èªDaily Digestã‚’ç”Ÿæˆï¼ˆMarkdownï¼‰
6. noteç”¨ã®æ—¥æœ¬èªDaily Digestã‚’ç”Ÿæˆï¼ˆMarkdownï¼‰
7. Google Sheetsç”¨ã®CSVã‚’å‡ºåŠ›
8. Twitter/XæŠ•ç¨¿ç”¨ã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›

ä½¿ã„æ–¹:
  python3 run_daily.py              # æœ¬æ—¥ã®äºˆæ¸¬ã‚’ç”Ÿæˆ
  python3 run_daily.py 2026-03-27   # æŒ‡å®šæ—¥ã®äºˆæ¸¬ã‚’ç”Ÿæˆ

å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
  pip3 install MLB-StatsAPI pandas scikit-learn xgboost gspread
"""

import os
import sys
import pickle
import json
import time
import logging
import traceback
from datetime import datetime, timedelta
from pathlib import Path

import pandas as pd
import numpy as np

# MLB Stats API
try:
    import statsapi
    STATSAPI_AVAILABLE = True
except ImportError:
    STATSAPI_AVAILABLE = False

# Google Sheetsï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import gspread
    from google.oauth2.service_account import Credentials as ServiceAccountCredentials
    SHEETS_AVAILABLE = True
except ImportError:
    SHEETS_AVAILABLE = False

# Anthropic APIï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    from article_generator_template import ArticleGenerator
    ARTICLE_GEN_AVAILABLE = True
except ImportError:
    ARTICLE_GEN_AVAILABLE = False

# ========================================================
# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
# ========================================================
LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO').upper()
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL, logging.INFO),
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
)
logger = logging.getLogger(__name__)

# ========================================================
# è¨­å®š
# ========================================================
PROJECT_DIR = Path(__file__).parent
MODELS_DIR = PROJECT_DIR / "models"
DATA_DIR = PROJECT_DIR / "data"
CREDENTIALS_PATH = PROJECT_DIR / "credentials.json"
SPREADSHEET_NAME = "Moneyball Dojo DB"

# ãƒªãƒˆãƒ©ã‚¤è¨­å®š
MAX_RETRIES = 3
RETRY_DELAYS = [2, 4, 8]  # seconds


# ========================================================
# 1. å…¨ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# ========================================================
def load_all_models():
    """å…¨å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    print("[1/9] Loading all trained models...")

    models = {}

    model_files = {
        'moneyline': MODELS_DIR / 'model_moneyline.pkl',
        'over_under': MODELS_DIR / 'model_over_under.pkl',
        'run_line': MODELS_DIR / 'model_run_line.pkl',
        'f5_moneyline': MODELS_DIR / 'model_f5_moneyline.pkl',
        'pitcher_k': MODELS_DIR / 'model_pitcher_k.pkl',
        'batter_props': MODELS_DIR / 'model_batter_props.pkl',
        'nrfi': MODELS_DIR / 'model_nrfi.pkl',
        'stolen_bases': MODELS_DIR / 'model_stolen_bases.pkl',
        'pitcher_outs': MODELS_DIR / 'model_pitcher_outs.pkl',
    }

    for name, path in model_files.items():
        if path.exists():
            with open(path, 'rb') as f:
                models[name] = pickle.load(f)
            print(f"  âœ“ {name}")
        else:
            print(f"  âš  {name} not found â€” skipping")

    if 'moneyline' not in models:
        # æ—§model.pklã‚’è©¦ã™
        legacy = PROJECT_DIR / "model.pkl"
        if legacy.exists():
            with open(legacy, 'rb') as f:
                models['moneyline'] = pickle.load(f)
            print(f"  âœ“ moneyline (legacy model.pkl)")
        else:
            print("  âŒ No moneyline model found. Run train_all_models.py first.")
            sys.exit(1)

    print(f"  â†’ {len(models)} models loaded")
    return models


# ========================================================
# 2. å½“æ—¥ã®è©¦åˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—
# ========================================================
def get_todays_schedule(target_date):
    """MLB Stats APIã‹ã‚‰å½“æ—¥ã®è©¦åˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—"""
    print(f"[2/9] Fetching schedule for {target_date}...")

    if not STATSAPI_AVAILABLE:
        print("  âŒ statsapi not installed. Run: pip3 install MLB-StatsAPI")
        sys.exit(1)

    try:
        sched = statsapi.schedule(
            start_date=target_date,
            end_date=target_date,
            sportId=1
        )
    except Exception as e:
        print(f"  âŒ MLB API error: {e}")
        print("  â†’ Check your internet connection")
        sys.exit(1)

    games = []
    for game in sched:
        game_type = game.get('game_type', '')
        if game_type not in ('R', 'S', 'E', 'W'):  # Regular, Spring, Exhibition, WBC
            continue

        games.append({
            'game_id': game.get('game_id', ''),
            'date': target_date,
            'home_team': game.get('home_name', ''),
            'away_team': game.get('away_name', ''),
            'home_pitcher': game.get('home_probable_pitcher', 'TBA'),
            'away_pitcher': game.get('away_probable_pitcher', 'TBA'),
            'venue': game.get('venue_name', ''),
            'game_type': game_type,
            'status': game.get('status', ''),
        })

    print(f"  âœ“ Found {len(games)} games for {target_date}")
    return games


# ========================================================
# 3. ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ========================================================
def load_historical_data():
    """data/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    print("[3/9] Loading historical data...")

    # è©¦åˆãƒ‡ãƒ¼ã‚¿
    games_path = DATA_DIR / "games_2022_2025.csv"
    if not games_path.exists():
        games_path = DATA_DIR / "games_2022_2024.csv"
    
    if not games_path.exists():
        print(f"  âŒ data/games_2022_2025.csv not found!")
        print("  â†’ Run: python3 fetch_real_data.py")
        sys.exit(1)

    games_df = pd.read_csv(games_path)
    games_df['date'] = pd.to_datetime(games_df['date'])
    print(f"  âœ“ Loaded {len(games_df)} historical games")

    # ãƒãƒ¼ãƒ ã‚¹ã‚¿ãƒƒãƒ„
    team_stats = {}
    for year in [2022, 2023, 2024, 2025, 2026]:
        path = DATA_DIR / f"team_stats_{year}.csv"
        if path.exists():
            team_stats[year] = pd.read_csv(path)

    latest_year = max(team_stats.keys()) if team_stats else 2024
    print(f"  âœ“ Team stats: {sorted(team_stats.keys())}")

    # æŠ•æ‰‹ãƒ‡ãƒ¼ã‚¿ï¼ˆK propsç”¨ï¼‰
    pitcher_stats = {}
    for year in [2022, 2023, 2024, 2025, 2026]:
        path = DATA_DIR / f"pitcher_stats_{year}.csv"
        if path.exists():
            pitcher_stats[year] = pd.read_csv(path)

    if pitcher_stats:
        latest_pitcher_year = max(pitcher_stats.keys())
        print(f"  âœ“ Pitcher stats: {sorted(pitcher_stats.keys())}")
    else:
        latest_pitcher_year = None
        print("  âš  No pitcher stats â€” K Props will be skipped")

    # æ‰“è€…ãƒ‡ãƒ¼ã‚¿ï¼ˆbatter propsç”¨ï¼‰
    batter_stats = {}
    for year in [2022, 2023, 2024, 2025, 2026]:
        path = DATA_DIR / f"batter_stats_{year}.csv"
        if path.exists():
            batter_stats[year] = pd.read_csv(path)

    if batter_stats:
        latest_batter_year = max(batter_stats.keys())
        print(f"  âœ“ Batter stats: {sorted(batter_stats.keys())}")
    else:
        latest_batter_year = None
        print("  âš  No batter stats â€” Batter Props will be skipped")

    return games_df, team_stats, latest_year, pitcher_stats, latest_pitcher_year, batter_stats, latest_batter_year


# ========================================================
# 4. ãƒãƒ¼ãƒ ã‚¹ã‚¿ãƒƒãƒ„è¨ˆç®—
# ========================================================
def compute_team_overall_stats(games_df, year):
    """æŒ‡å®šå¹´ã®ãƒãƒ¼ãƒ å…¨ä½“æˆç¸¾ã‚’è¨ˆç®—"""
    year_games = games_df[games_df['year'] == year]
    all_teams = set(year_games['home_team'].unique()) | set(year_games['away_team'].unique())

    records = {}
    for team in all_teams:
        home_g = year_games[year_games['home_team'] == team]
        away_g = year_games[year_games['away_team'] == team]

        home_wins = int(home_g['home_win'].sum())
        away_wins = len(away_g) - int(away_g['home_win'].sum())
        total_wins = home_wins + away_wins
        total_games = len(home_g) + len(away_g)

        home_rs = home_g['home_score'].sum()
        away_rs = away_g['away_score'].sum()
        home_ra = home_g['away_score'].sum()
        away_ra = away_g['home_score'].sum()

        total_rs = home_rs + away_rs
        total_ra = home_ra + away_ra

        win_pct = total_wins / total_games if total_games > 0 else 0.5
        avg_rs = total_rs / total_games if total_games > 0 else 4.5
        avg_ra = total_ra / total_games if total_games > 0 else 4.5
        run_diff = (total_rs - total_ra) / total_games if total_games > 0 else 0
        pythag = total_rs**1.83 / (total_rs**1.83 + total_ra**1.83) if (total_rs + total_ra) > 0 else 0.5

        home_win_pct = home_g['home_win'].mean() if len(home_g) > 0 else 0.54
        away_win_pct = (1 - away_g['home_win']).mean() if len(away_g) > 0 else 0.46
        home_avg_rs = home_g['home_score'].mean() if len(home_g) > 0 else 4.5
        away_avg_rs = away_g['away_score'].mean() if len(away_g) > 0 else 4.5

        records[team] = {
            'win_pct': win_pct, 'avg_rs': avg_rs, 'avg_ra': avg_ra,
            'run_diff': run_diff, 'pythag': pythag,
            'home_win_pct': home_win_pct, 'away_win_pct': away_win_pct,
            'home_avg_rs': home_avg_rs, 'away_avg_rs': away_avg_rs,
        }

    return records


def compute_team_rolling_stats(games_df, window=15):
    """å„ãƒãƒ¼ãƒ ã®ç›´è¿‘Nè©¦åˆã®ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¹ã‚¿ãƒƒãƒ„"""
    games_sorted = games_df.sort_values('date').reset_index(drop=True)
    all_teams = set(games_sorted['home_team'].unique()) | set(games_sorted['away_team'].unique())

    latest_rolling = {}

    for team in all_teams:
        mask = (games_sorted['home_team'] == team) | (games_sorted['away_team'] == team)
        team_games = games_sorted[mask].copy()

        team_games['team_win'] = np.where(
            team_games['home_team'] == team,
            team_games['home_win'],
            1 - team_games['home_win']
        )
        team_games['team_runs'] = np.where(
            team_games['home_team'] == team,
            team_games['home_score'],
            team_games['away_score']
        )
        team_games['opp_runs'] = np.where(
            team_games['home_team'] == team,
            team_games['away_score'],
            team_games['home_score']
        )

        recent = team_games.tail(window)
        if len(recent) >= 5:
            latest_rolling[team] = {
                'rolling_win_pct': recent['team_win'].mean(),
                'rolling_rs': recent['team_runs'].mean(),
                'rolling_ra': recent['opp_runs'].mean(),
                'rolling_run_diff': (recent['team_runs'] - recent['opp_runs']).mean(),
            }
        else:
            latest_rolling[team] = {
                'rolling_win_pct': 0.5, 'rolling_rs': 4.5,
                'rolling_ra': 4.5, 'rolling_run_diff': 0.0,
            }

    return latest_rolling


def get_api_team_stats(team_name, year, team_stats_dict):
    """APIå–å¾—æ¸ˆã¿ã®ãƒãƒ¼ãƒ æ‰“æ’ƒãƒ»æŠ•æ‰‹æŒ‡æ¨™"""
    defaults = {'BA': 0.248, 'OBP': 0.315, 'SLG': 0.395, 'ERA': 4.12, 'WHIP': 1.28, 'HR': 0, 'SB': 0, 'OPS': 0.710}

    if year not in team_stats_dict:
        return defaults

    ts = team_stats_dict[year]
    team_row = ts[ts['team_name'] == team_name]
    if len(team_row) == 0:
        return defaults

    r = team_row.iloc[0]
    return {
        'BA': float(r.get('BA', 0.248)),
        'OBP': float(r.get('OBP', 0.315)),
        'SLG': float(r.get('SLG', 0.395)),
        'ERA': float(r.get('ERA', 4.12)),
        'WHIP': float(r.get('WHIP', 1.28)),
        'HR': int(r.get('HR', 0)),
        'SB': int(r.get('SB', 0)),
        'OPS': float(r.get('OPS', 0.710)),
    }


# ========================================================
# 5. ç‰¹å¾´é‡ç”Ÿæˆ + å…¨ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
# ========================================================
def build_game_features(home, away, overall_stats, rolling_stats, team_stats_dict, latest_year):
    """1è©¦åˆåˆ†ã®ã‚²ãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ37ç‰¹å¾´é‡ï¼‰"""
    home_season = overall_stats[home]
    away_season = overall_stats[away]
    home_api = get_api_team_stats(home, latest_year, team_stats_dict)
    away_api = get_api_team_stats(away, latest_year, team_stats_dict)
    home_rolling = rolling_stats.get(home, {'rolling_win_pct': 0.5, 'rolling_rs': 4.5, 'rolling_ra': 4.5, 'rolling_run_diff': 0})
    away_rolling = rolling_stats.get(away, {'rolling_win_pct': 0.5, 'rolling_rs': 4.5, 'rolling_ra': 4.5, 'rolling_run_diff': 0})

    features = {
        # Season-level
        'win_pct_diff': home_season['win_pct'] - away_season['win_pct'],
        'pythag_diff': home_season['pythag'] - away_season['pythag'],
        'home_run_diff': home_season['run_diff'],
        'away_run_diff': away_season['run_diff'],
        'run_diff_diff': home_season['run_diff'] - away_season['run_diff'],
        # Batting
        'home_BA': home_api['BA'], 'away_BA': away_api['BA'],
        'BA_diff': home_api['BA'] - away_api['BA'],
        'home_OBP': home_api['OBP'], 'away_OBP': away_api['OBP'],
        'OBP_diff': home_api['OBP'] - away_api['OBP'],
        'home_SLG': home_api['SLG'], 'away_SLG': away_api['SLG'],
        'SLG_diff': home_api['SLG'] - away_api['SLG'],
        # Pitching
        'home_ERA': home_api['ERA'], 'away_ERA': away_api['ERA'],
        'ERA_diff': away_api['ERA'] - home_api['ERA'],
        'home_WHIP': home_api['WHIP'], 'away_WHIP': away_api['WHIP'],
        'WHIP_diff': away_api['WHIP'] - home_api['WHIP'],
        # Home/Away splits
        'home_team_home_wpct': home_season['home_win_pct'],
        'away_team_away_wpct': away_season['away_win_pct'],
        'home_away_split_diff': home_season['home_win_pct'] - away_season['away_win_pct'],
        # Rolling
        'home_rolling_wpct': home_rolling['rolling_win_pct'],
        'away_rolling_wpct': away_rolling['rolling_win_pct'],
        'rolling_wpct_diff': home_rolling['rolling_win_pct'] - away_rolling['rolling_win_pct'],
        'home_rolling_rs': home_rolling['rolling_rs'],
        'away_rolling_rs': away_rolling['rolling_rs'],
        'home_rolling_run_diff': home_rolling['rolling_run_diff'],
        'away_rolling_run_diff': away_rolling['rolling_run_diff'],
        'rolling_run_diff_diff': home_rolling['rolling_run_diff'] - away_rolling['rolling_run_diff'],
        # Composite
        'home_offensive_strength': (home_api['BA'] + home_api['OBP'] + home_api['SLG']) / 3,
        'away_offensive_strength': (away_api['BA'] + away_api['OBP'] + away_api['SLG']) / 3,
        'home_defensive_strength': 1 / (1 + home_api['ERA']) * 1 / (1 + home_api['WHIP']),
        'away_defensive_strength': 1 / (1 + away_api['ERA']) * 1 / (1 + away_api['WHIP']),
        'offensive_diff': ((home_api['BA'] + home_api['OBP'] + home_api['SLG']) -
                          (away_api['BA'] + away_api['OBP'] + away_api['SLG'])) / 3,
        'defensive_diff': (1/(1+home_api['ERA']) * 1/(1+home_api['WHIP'])) -
                         (1/(1+away_api['ERA']) * 1/(1+away_api['WHIP'])),
    }

    return features, home_season, away_season, home_api, away_api, home_rolling, away_rolling


def predict_with_model(model_data, features, feature_cols_override=None):
    """æ±ç”¨ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬é–¢æ•°"""
    model = model_data['model']
    scaler = model_data['scaler']
    feature_cols = feature_cols_override or model_data['feature_cols']

    feat_df = pd.DataFrame([features])

    # ä¸è¶³/ä½™åˆ†åˆ—ã®èª¿æ•´
    missing = set(feature_cols) - set(feat_df.columns)
    for col in missing:
        feat_df[col] = 0.0
    extra = set(feat_df.columns) - set(feature_cols)
    if extra:
        feat_df = feat_df.drop(columns=list(extra))

    feat_df = feat_df[feature_cols].astype(float)
    feat_scaled = scaler.transform(feat_df)
    feat_scaled_df = pd.DataFrame(feat_scaled, columns=feature_cols)

    return model, feat_scaled_df


def build_ou_extra_features(home_api, away_api, home_season, away_season, home_rolling, away_rolling):
    """Over/Underç”¨ã®è¿½åŠ ç‰¹å¾´é‡"""
    return {
        'combined_avg_rs': (home_season['avg_rs'] + away_season['avg_rs']) / 2,
        'combined_avg_ra': (home_season['avg_ra'] + away_season['avg_ra']) / 2,
        'total_expected_runs': home_season['avg_rs'] + away_season['avg_rs'],
        'combined_ERA': (home_api['ERA'] + away_api['ERA']) / 2,
        'combined_WHIP': (home_api['WHIP'] + away_api['WHIP']) / 2,
        'combined_BA': (home_api['BA'] + away_api['BA']) / 2,
        'combined_OBP': (home_api['OBP'] + away_api['OBP']) / 2,
        'combined_SLG': (home_api['SLG'] + away_api['SLG']) / 2,
        'combined_OPS': (home_api['OPS'] + away_api['OPS']) / 2,
        'scoring_environment': (home_season['avg_rs'] + away_season['avg_rs'] +
                               home_season['avg_ra'] + away_season['avg_ra']) / 4,
        'pitching_quality': -(home_api['ERA'] + away_api['ERA']) / 2,
        'hitting_power': (home_api['SLG'] + away_api['SLG']) / 2,
        'combined_rolling_rs': (home_rolling['rolling_rs'] + away_rolling['rolling_rs']) / 2,
        'combined_rolling_ra': (home_rolling['rolling_ra'] + away_rolling['rolling_ra']) / 2,
        'rolling_total_runs': home_rolling['rolling_rs'] + away_rolling['rolling_rs'],
    }


def generate_all_predictions(games, models, games_df, team_stats_dict, latest_year,
                              pitcher_stats, latest_pitcher_year,
                              batter_stats, latest_batter_year):
    """å…¨6ãƒ¢ãƒ‡ãƒ«ã§å…¨è©¦åˆã®äºˆæ¸¬ã‚’ç”Ÿæˆ"""
    print("[5/9] Generating predictions with all models...")

    overall_stats = compute_team_overall_stats(games_df, latest_year)
    rolling_stats = compute_team_rolling_stats(games_df, window=15)

    all_predictions = []
    skipped = 0

    for game in games:
        home = game['home_team']
        away = game['away_team']

        if home not in overall_stats or away not in overall_stats:
            print(f"  âš  Unknown team: {home} or {away} â€” skipping")
            skipped += 1
            continue

        # ã‚²ãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ç‰¹å¾´é‡
        features, home_season, away_season, home_api, away_api, home_rolling, away_rolling = \
            build_game_features(home, away, overall_stats, rolling_stats, team_stats_dict, latest_year)

        pred = {**game}

        # --- MONEYLINE ---
        if 'moneyline' in models:
            try:
                ml_model, ml_feat = predict_with_model(models['moneyline'], features)
                prob = ml_model.predict_proba(ml_feat)[0][1]
                pred['ml_prob'] = round(float(prob), 4)
                pred['ml_pick'] = 'HOME' if prob > 0.5 else 'AWAY'

                # ãƒãƒ¼ã‚±ãƒƒãƒˆã‚ªãƒƒã‚ºæ¨å®š
                implied = (home_season['win_pct'] * 0.54) / (home_season['win_pct'] * 0.54 + away_season['win_pct'] * 0.46)
                implied = max(0.30, min(0.70, implied))
                pred['ml_implied'] = round(float(implied), 4)
                pred['ml_edge'] = round(float(prob - implied), 4)

                abs_edge = abs(pred['ml_edge'])
                if abs_edge >= 0.08:
                    pred['ml_confidence'] = 'STRONG'
                elif abs_edge >= 0.04:
                    pred['ml_confidence'] = 'MODERATE'
                elif abs(prob - 0.5) < 0.03:
                    pred['ml_confidence'] = 'PASS'
                else:
                    pred['ml_confidence'] = 'LEAN'

                if pred['ml_confidence'] == 'PASS':
                    pred['ml_pick'] = 'PASS'
            except Exception as e:
                pred['ml_prob'] = 0.5
                pred['ml_pick'] = 'N/A'
                pred['ml_edge'] = 0.0
                pred['ml_confidence'] = 'N/A'

        # --- OVER/UNDER ---
        if 'over_under' in models:
            try:
                ou_data = models['over_under']
                ou_extra = build_ou_extra_features(home_api, away_api, home_season, away_season, home_rolling, away_rolling)
                ou_features = {**features, **ou_extra}

                # Regression model for total runs
                reg_model = ou_data['regressor']  # regressor
                reg_scaler = ou_data['scaler']
                reg_feat_cols = ou_data['feature_cols']

                reg_df = pd.DataFrame([ou_features])
                for col in set(reg_feat_cols) - set(reg_df.columns):
                    reg_df[col] = 0.0
                reg_df = reg_df[reg_feat_cols].astype(float)
                reg_scaled = reg_scaler.transform(reg_df)
                pred_total = reg_model.predict(pd.DataFrame(reg_scaled, columns=reg_feat_cols))[0]

                pred['ou_predicted_total'] = round(float(pred_total), 2)

                # Classify over/under at common lines
                for line in [7.5, 8.0, 8.5, 9.0, 9.5]:
                    margin = pred_total - line
                    if abs(margin) > 1.5:
                        conf = 'STRONG'
                    elif abs(margin) > 0.75:
                        conf = 'MODERATE'
                    elif abs(margin) > 0.3:
                        conf = 'LEAN'
                    else:
                        conf = 'PASS'
                    side = 'OVER' if margin > 0 else 'UNDER'
                    pred[f'ou_{line}_pick'] = side if conf != 'PASS' else 'PASS'
                    pred[f'ou_{line}_confidence'] = conf
                    pred[f'ou_{line}_margin'] = round(float(margin), 2)

            except Exception as e:
                pred['ou_predicted_total'] = None

        # --- RUN LINE ---
        if 'run_line' in models:
            try:
                rl_model, rl_feat = predict_with_model(models['run_line'], features)
                prob = rl_model.predict_proba(rl_feat)[0][1]
                pred['rl_covers_prob'] = round(float(prob), 4)
                pred['rl_pick'] = 'HOME -1.5' if prob > 0.5 else 'AWAY +1.5'

                # Historical base rate: home team covers -1.5 ~35.7% of the time.
                # Confidence reflects deviation from that base rate, not from 0.5.
                RL_BASE_RATE = 0.357
                abs_edge = abs(prob - RL_BASE_RATE)
                if abs_edge >= 0.12:
                    pred['rl_confidence'] = 'STRONG'
                elif abs_edge >= 0.06:
                    pred['rl_confidence'] = 'MODERATE'
                elif abs_edge < 0.02:
                    pred['rl_confidence'] = 'PASS'
                else:
                    pred['rl_confidence'] = 'LEAN'

                if pred['rl_confidence'] == 'PASS':
                    pred['rl_pick'] = 'PASS'
            except Exception as e:
                pred['rl_covers_prob'] = 0.5
                pred['rl_pick'] = 'N/A'
                pred['rl_confidence'] = 'N/A'

        # --- FIRST 5 INNINGS ---
        if 'f5_moneyline' in models:
            try:
                f5_model, f5_feat = predict_with_model(models['f5_moneyline'], features)
                prob = f5_model.predict_proba(f5_feat)[0][1]
                pred['f5_prob'] = round(float(prob), 4)
                pred['f5_pick'] = 'HOME' if prob > 0.5 else 'AWAY'

                abs_edge = abs(prob - 0.5)
                if abs_edge >= 0.08:
                    pred['f5_confidence'] = 'STRONG'
                elif abs_edge >= 0.04:
                    pred['f5_confidence'] = 'MODERATE'
                elif abs_edge < 0.03:
                    pred['f5_confidence'] = 'PASS'
                else:
                    pred['f5_confidence'] = 'LEAN'

                if pred['f5_confidence'] == 'PASS':
                    pred['f5_pick'] = 'PASS'
            except Exception as e:
                pred['f5_prob'] = 0.5
                pred['f5_pick'] = 'N/A'
                pred['f5_confidence'] = 'N/A'

        # --- PITCHER K PROPS ---
        if 'pitcher_k' in models and latest_pitcher_year:
            pitcher_df = pitcher_stats[latest_pitcher_year]

            for side, pitcher_name_key in [('home', 'home_pitcher'), ('away', 'away_pitcher')]:
                pitcher_name = game.get(pitcher_name_key, 'TBA')
                if pitcher_name == 'TBA' or not pitcher_name:
                    pred[f'{side}_pitcher_k_pred'] = None
                    continue

                try:
                    pk_data = models['pitcher_k']
                    pk_model = pk_data['model']
                    pk_scaler = pk_data['scaler']
                    pk_feat_cols = pk_data['feature_cols']

                    # æŠ•æ‰‹ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ
                    p_row = pitcher_df[pitcher_df['name'].str.contains(pitcher_name.split()[-1], case=False, na=False)]
                    if len(p_row) == 0:
                        pred[f'{side}_pitcher_k_pred'] = None
                        continue

                    p = p_row.iloc[0]
                    pk_features = {}
                    for col in pk_feat_cols:
                        if col in p.index:
                            pk_features[col] = float(p[col])
                        elif col == 'K_BB_ratio':
                            k9 = float(p.get('K_per_9', 8.0))
                            bb9 = float(p.get('BB_per_9', 3.0))
                            pk_features[col] = k9 / bb9 if bb9 > 0 else 3.0
                        elif col == 'hits_per_9':
                            ip = float(p.get('innings', 100))
                            ha = float(p.get('hits_allowed', 150))
                            pk_features[col] = ha * 9 / ip if ip > 0 else 9.0
                        else:
                            pk_features[col] = 0.0

                    pk_df = pd.DataFrame([pk_features])[pk_feat_cols].astype(float)
                    pk_scaled = pk_scaler.transform(pk_df)
                    k_pred = pk_model.predict(pd.DataFrame(pk_scaled, columns=pk_feat_cols))[0]

                    pred[f'{side}_pitcher_k_pred'] = round(float(k_pred), 2)
                    pred[f'{side}_pitcher_name'] = pitcher_name

                    # K Props lines
                    for line in [4.5, 5.5, 6.5, 7.5]:
                        margin = k_pred - line
                        if abs(margin) > 1.5:
                            conf = 'STRONG'
                        elif abs(margin) > 0.75:
                            conf = 'MODERATE'
                        elif abs(margin) > 0.3:
                            conf = 'LEAN'
                        else:
                            conf = 'PASS'
                        side_pick = 'OVER' if margin > 0 else 'UNDER'
                        pred[f'{side}_k_{line}_pick'] = side_pick if conf != 'PASS' else 'PASS'
                        pred[f'{side}_k_{line}_conf'] = conf

                except Exception:
                    pred[f'{side}_pitcher_k_pred'] = None

        # --- BATTER PROPS ---
        if 'batter_props' in models and latest_batter_year:
            # ãƒãƒƒã‚¿ãƒ¼ã¯å¤šã™ãã‚‹ã®ã§ã€å„ãƒãƒ¼ãƒ ä¸Šä½3æ‰“è€…ã®ã¿äºˆæ¸¬
            batter_df = batter_stats[latest_batter_year]

            for side, team_name in [('home', home), ('away', away)]:
                try:
                    bp_data = models['batter_props']
                    hit_model = bp_data['hit_model']   # hit model
                    hr_model = bp_data.get('hr_model')  # hr model
                    bp_scaler = bp_data['scaler']
                    bp_feat_cols = bp_data['feature_cols']

                    # ãƒãƒ¼ãƒ ã®æ‰“è€…ã‚’å–å¾—
                    team_batters = batter_df[batter_df['team_name'].str.contains(team_name.split()[-1], case=False, na=False)]
                    if len(team_batters) == 0:
                        continue

                    # OPSä¸Šä½3äºº
                    top_batters = team_batters.nlargest(3, 'OPS') if 'OPS' in team_batters.columns else team_batters.head(3)

                    batter_preds = []
                    for _, b in top_batters.iterrows():
                        bp_features = {}
                        for col in bp_feat_cols:
                            if col in b.index:
                                bp_features[col] = float(b[col])
                            elif col == 'ISO':
                                bp_features[col] = float(b.get('SLG', 0.395)) - float(b.get('BA', 0.248))
                            elif col == 'BB_rate':
                                pa = float(b.get('plate_appearances', 500))
                                bb = float(b.get('walks', 50))
                                bp_features[col] = bb / pa if pa > 0 else 0.08
                            elif col == 'AB_per_HR':
                                ab = float(b.get('at_bats', 500))
                                hr = float(b.get('home_runs', 15))
                                bp_features[col] = ab / hr if hr > 0 else 40
                            else:
                                bp_features[col] = 0.0

                        bp_df = pd.DataFrame([bp_features])[bp_feat_cols].astype(float)
                        bp_scaled = bp_scaler.transform(bp_df)
                        bp_scaled_df = pd.DataFrame(bp_scaled, columns=bp_feat_cols)

                        hit_pred = hit_model.predict(bp_scaled_df)[0]
                        hr_pred = hr_model.predict(bp_scaled_df)[0] if hr_model else 0

                        batter_preds.append({
                            'name': b.get('name', 'Unknown'),
                            'hits_pred': round(float(hit_pred), 3),
                            'hr_pred': round(float(hr_pred), 4),
                        })

                    pred[f'{side}_batter_preds'] = batter_preds

                except Exception:
                    pass

        # --- NRFI/YRFI (v2: with pitcher + park factors) ---
        if 'nrfi' in models:
            try:
                nrfi_data = models['nrfi']
                nrfi_model = nrfi_data['model']
                nrfi_scaler = nrfi_data['scaler']
                nrfi_feat_cols = nrfi_data['feature_cols']

                # å…ˆç™ºæŠ•æ‰‹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
                def _get_pitcher_stats(pitcher_name, year, pitcher_stats_dict):
                    defaults = {'ERA': 4.12, 'WHIP': 1.28, 'K_per_9': 8.5}
                    if not isinstance(pitcher_name, str) or not pitcher_name or pitcher_name == 'TBA':
                        return defaults
                    if year not in pitcher_stats_dict:
                        return defaults
                    ps = pitcher_stats_dict[year]
                    match = ps[ps['name'] == pitcher_name]
                    if len(match) == 0:
                        last_name = pitcher_name.split()[-1]
                        match = ps[ps['name'].str.contains(last_name, case=False, na=False)]
                    if len(match) == 0:
                        return defaults
                    p = match.iloc[0]
                    return {
                        'ERA': float(p.get('ERA', 4.12)),
                        'WHIP': float(p.get('WHIP', 1.28)),
                        'K_per_9': float(p.get('K_per_9', 8.5)),
                    }

                # æŠ•æ‰‹ãƒ‡ãƒ¼ã‚¿å–å¾—
                hp_name = game.get('home_pitcher', 'TBA')
                ap_name = game.get('away_pitcher', 'TBA')
                hp = _get_pitcher_stats(hp_name, latest_year, pitcher_stats if pitcher_stats else {})
                ap = _get_pitcher_stats(ap_name, latest_year, pitcher_stats if pitcher_stats else {})

                nrfi_features = {
                    # 1å›ç‰¹åŒ–ãƒãƒ¼ãƒ çµ±è¨ˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã¯ç°¡æ˜“æ¨å®šï¼‰
                    'home_1st_rs': home_season['avg_rs'] * 0.11,
                    'home_1st_ra': home_season['avg_ra'] * 0.11,
                    'away_1st_rs': away_season['avg_rs'] * 0.11,
                    'away_1st_ra': away_season['avg_ra'] * 0.11,
                    'combined_1st_ra': (home_season['avg_ra'] + away_season['avg_ra']) * 0.055,
                    'combined_1st_rs': (home_season['avg_rs'] + away_season['avg_rs']) * 0.055,
                    # å…ˆç™ºæŠ•æ‰‹
                    'home_starter_era': hp['ERA'],
                    'away_starter_era': ap['ERA'],
                    'home_starter_whip': hp['WHIP'],
                    'away_starter_whip': ap['WHIP'],
                    'home_starter_k9': hp['K_per_9'],
                    'away_starter_k9': ap['K_per_9'],
                    'starter_era_diff': hp['ERA'] - ap['ERA'],
                    'starter_whip_diff': hp['WHIP'] - ap['WHIP'],
                    'combined_starter_era': (hp['ERA'] + ap['ERA']) / 2,
                    # çƒå ´ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã¯ãƒªãƒ¼ã‚°å¹³å‡ã‚’ä½¿ç”¨ï¼‰
                    'venue_nrfi_rate': 0.511,
                    # ãƒãƒ¼ãƒ çµ±è¨ˆ
                    'home_era': home_api['ERA'],
                    'away_era': away_api['ERA'],
                    'home_obp': home_api['OBP'],
                    'away_obp': away_api['OBP'],
                    'total_runs_per_game': home_season['avg_rs'] + away_season['avg_rs'],
                }

                nrfi_df = pd.DataFrame([nrfi_features])
                for col in set(nrfi_feat_cols) - set(nrfi_df.columns):
                    nrfi_df[col] = 0.0
                nrfi_df = nrfi_df[nrfi_feat_cols].astype(float)
                nrfi_scaled = nrfi_scaler.transform(nrfi_df)
                prob = nrfi_model.predict_proba(pd.DataFrame(nrfi_scaled, columns=nrfi_feat_cols))[0][1]

                pred['nrfi_prob'] = round(float(prob), 4)
                pred['nrfi_pick'] = 'NRFI' if prob > 0.5 else 'YRFI'

                abs_edge = abs(prob - 0.5)
                if abs_edge >= 0.10:
                    pred['nrfi_confidence'] = 'STRONG'
                elif abs_edge >= 0.05:
                    pred['nrfi_confidence'] = 'MODERATE'
                else:
                    pred['nrfi_confidence'] = 'LEAN'
            except Exception:
                pred['nrfi_pick'] = 'N/A'

        # --- STOLEN BASES ---
        if 'stolen_bases' in models:
            try:
                sb_data = models['stolen_bases']
                sb_model = sb_data['model']
                sb_scaler = sb_data['scaler']
                sb_feat_cols = sb_data['feature_cols']

                sb_features = {
                    'home_sb_per_game': home_season.get('sb_per_game', 0.7),
                    'away_sb_per_game': away_season.get('sb_per_game', 0.7),
                    'combined_sb_per_game': home_season.get('sb_per_game', 0.7) + away_season.get('sb_per_game', 0.7),
                    'home_speed_proxy': home_api.get('stolen_bases', 10) / 162,
                    'away_speed_proxy': away_api.get('stolen_bases', 10) / 162,
                    'home_win_pct': home_season['win_pct'],
                    'away_win_pct': away_season['win_pct'],
                    'home_runs_per_game': home_season['avg_rs'],
                    'away_runs_per_game': away_season['avg_rs'],
                    'home_obp': home_api['OBP'],
                    'away_obp': away_api['OBP'],
                }

                sb_df = pd.DataFrame([sb_features])
                for col in set(sb_feat_cols) - set(sb_df.columns):
                    sb_df[col] = 0.0
                sb_df = sb_df[sb_feat_cols].astype(float)
                sb_scaled = sb_scaler.transform(sb_df)
                prob = sb_model.predict_proba(pd.DataFrame(sb_scaled, columns=sb_feat_cols))[0][1]

                pred['sb_prob'] = round(float(prob), 4)
                pred['sb_pick'] = 'OVER' if prob > 0.5 else 'UNDER'
                pred['sb_confidence'] = 'STRONG' if abs(prob-0.5) > 0.1 else 'MODERATE' if abs(prob-0.5) > 0.05 else 'LEAN'
            except Exception:
                pred['sb_pick'] = 'N/A'

        # --- PITCHER OUTS ---
        if 'pitcher_outs' in models and latest_pitcher_year:
            pitch_df = pitcher_stats[latest_pitcher_year]
            for side, p_name_key in [('home', 'home_pitcher'), ('away', 'away_pitcher')]:
                p_name = game.get(p_name_key, 'TBA')
                if p_name == 'TBA': continue
                
                try:
                    out_data = models['pitcher_outs']
                    out_model = out_data['model']
                    out_scaler = out_data['scaler']
                    out_feat_cols = out_data['feature_cols']

                    p_row = pitch_df[pitch_df['name'].str.contains(p_name.split()[-1], case=False, na=False)]
                    if len(p_row) == 0: continue
                    p = p_row.iloc[0]

                    out_features = {col: float(p.get(col, 0)) for col in out_feat_cols}
                    # Add team context
                    team_stat = home_season if side == 'home' else away_season
                    out_features['team_win_pct'] = team_stat['win_pct']
                    out_features['team_era'] = team_stat['avg_ra'] # Proxy
                    out_features['team_runs_per_game'] = team_stat['avg_rs']

                    out_df = pd.DataFrame([out_features])
                    for col in set(out_feat_cols) - set(out_df.columns):
                        out_df[col] = 0.0
                    out_df = out_df[out_feat_cols].astype(float)
                    out_scaled = out_scaler.transform(out_df)
                    outs_pred = out_model.predict(pd.DataFrame(out_scaled, columns=out_feat_cols))[0]
                    
                    pred[f'{side}_outs_pred'] = round(float(outs_pred), 2)
                    # Convert to innings format (e.g. 5.66 -> 5.2)
                    full_inns = int(outs_pred)
                    frac = outs_pred - full_inns
                    if frac < 0.15: outs_label = f"{full_inns}.0"
                    elif frac < 0.45: outs_label = f"{full_inns}.1"
                    else: outs_label = f"{full_inns}.2"
                    pred[f'{side}_outs_label'] = outs_label
                except Exception:
                    pass

        # è¿½åŠ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        pred['home_win_pct'] = round(float(home_season['win_pct']), 3)
        pred['away_win_pct'] = round(float(away_season['win_pct']), 3)
        pred['home_rolling_form'] = round(float(home_rolling['rolling_win_pct']), 3)
        pred['away_rolling_form'] = round(float(away_rolling['rolling_win_pct']), 3)

        all_predictions.append(pred)

    # Moneylineã‚¨ãƒƒã‚¸ã§ã‚½ãƒ¼ãƒˆ
    all_predictions.sort(key=lambda x: abs(x.get('ml_edge', 0)), reverse=True)

    print(f"  âœ“ Generated {len(all_predictions)} full predictions (skipped {skipped})")

    # ã‚µãƒãƒªãƒ¼
    if all_predictions and 'ml_confidence' in all_predictions[0]:
        strong = sum(1 for p in all_predictions if p.get('ml_confidence') == 'STRONG')
        moderate = sum(1 for p in all_predictions if p.get('ml_confidence') == 'MODERATE')
        lean = sum(1 for p in all_predictions if p.get('ml_confidence') == 'LEAN')
        passed = sum(1 for p in all_predictions if p.get('ml_confidence') == 'PASS')
        print(f"  â†’ ML: STRONG {strong} | MODERATE {moderate} | LEAN {lean} | PASS {passed}")

    return all_predictions


# ========================================================
# 6. Digestç”Ÿæˆ
# ========================================================
def edge_display(edge):
    """ã‚¨ãƒƒã‚¸è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if edge > 0.08:
        return f"+{edge*100:.1f}% ğŸ”¥"
    elif edge > 0.04:
        return f"+{edge*100:.1f}% ğŸ‘"
    elif edge > 0:
        return f"+{edge*100:.1f}%"
    elif edge > -0.03:
        return f"{edge*100:.1f}%"
    else:
        return f"{edge*100:.1f}% âš ï¸"


def generate_english_digest(predictions, target_date, models_loaded):
    """Substackç”¨è‹±èªãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ â€” å…¨å¸‚å ´å¯¾å¿œ"""
    print("[6/9] Generating English digest (Substack)...")

    if not predictions:
        return f"# Moneyball Dojo Daily Digest â€” {target_date}\n\nNo games scheduled today.\n"

    md = []
    md.append(f"# Moneyball Dojo Daily Digest â€” {target_date}")
    md.append("")
    active_models = len(models_loaded)
    md.append(f"*{len(predictions)} games analyzed across {active_models} AI models. Here's what the numbers say.*")
    md.append("")

    # Spring Training banner
    is_spring_training = any(p.get('game_type') == 'S' for p in predictions)
    if is_spring_training:
        md.append("> **Spring Training Notice:** Models are trained on regular season data (2022-2025).")
        md.append("> Spring Training games feature non-standard lineups, split squads, and pitchers on strict pitch counts.")
        md.append("> Treat all picks as directional signals, not high-conviction bets.")
        md.append("")

    md.append("---")
    md.append("")

    # === MONEYLINE TABLE ===
    actionable_ml = [p for p in predictions if p.get('ml_pick', 'N/A') not in ('PASS', 'N/A')]

    md.append("## Moneyline Picks")
    md.append("")
    md.append("| Matchup | Pick | Win Prob | Edge | Confidence |")
    md.append("|---------|------|----------|------|------------|")
    for p in predictions:
        matchup = f"{p['away_team']} @ {p['home_team']}"
        pick = p.get('ml_pick', 'N/A')
        prob = p.get('ml_prob', 0.5)
        e = p.get('ml_edge', 0)
        conf = p.get('ml_confidence', 'N/A')
        pick_d = f"**{pick}**" if conf in ('STRONG', 'MODERATE') else pick
        md.append(f"| {matchup} | {pick_d} | {prob*100:.1f}% | {edge_display(e)} | {conf} |")
    md.append("")

    # === OVER/UNDER ===
    if any(p.get('ou_predicted_total') for p in predictions):
        md.append("## Over/Under")
        md.append("")
        md.append("| Matchup | Predicted Total | O/U 8.5 | Margin | Confidence |")
        md.append("|---------|----------------|---------|--------|------------|")
        for p in predictions:
            if p.get('ou_predicted_total') is None:
                continue
            matchup = f"{p['away_team']} @ {p['home_team']}"
            total = p['ou_predicted_total']
            pick_85 = p.get('ou_8.5_pick', 'N/A')
            margin_85 = p.get('ou_8.5_margin', 0)
            conf_85 = p.get('ou_8.5_confidence', 'N/A')
            md.append(f"| {matchup} | {total:.1f} | {pick_85} | {margin_85:+.1f} | {conf_85} |")
        md.append("")

    # === RUN LINE ===
    rl_actionable = [p for p in predictions if p.get('rl_confidence') in ('STRONG', 'MODERATE')]
    if rl_actionable:
        md.append("## Run Line (-1.5)")
        md.append("")
        md.append("| Matchup | Pick | Home Cover Prob | Confidence |")
        md.append("|---------|------|-----------------|------------|")
        for p in rl_actionable:
            matchup = f"{p['away_team']} @ {p['home_team']}"
            pick = p.get('rl_pick', 'N/A')
            prob = p.get('rl_covers_prob', 0.357)
            conf = p.get('rl_confidence', 'N/A')
            md.append(f"| {matchup} | {pick} | {prob*100:.1f}% | {conf} |")
        md.append("")

    # === F5 MONEYLINE ===
    if any(p.get('f5_prob') for p in predictions):
        md.append("## First 5 Innings")
        md.append("")
        md.append("| Matchup | Pick | Win Prob | Confidence |")
        md.append("|---------|------|----------|------------|")
        for p in predictions:
            if p.get('f5_pick', 'N/A') == 'N/A':
                continue
            matchup = f"{p['away_team']} @ {p['home_team']}"
            pick = p.get('f5_pick', 'N/A')
            prob = p.get('f5_prob', 0.5)
            conf = p.get('f5_confidence', 'N/A')
            md.append(f"| {matchup} | {pick} | {prob*100:.1f}% | {conf} |")
        md.append("")

    # === NRFI/YRFI ===
    if any(p.get('nrfi_pick') for p in predictions):
        md.append("## NRFI/YRFI (No Runs First Inning)")
        md.append("")
        md.append("| Matchup | Pick | Prob | Confidence |")
        md.append("|---------|------|------|------------|")
        for p in predictions:
            if p.get('nrfi_pick', 'N/A') == 'N/A':
                continue
            matchup = f"{p['away_team']} @ {p['home_team']}"
            pick = p.get('nrfi_pick', 'N/A')
            prob = p.get('nrfi_prob', 0.5)
            conf = p.get('nrfi_confidence', 'N/A')
            md.append(f"| {matchup} | {pick} | {prob*100:.1f}% | {conf} |")
        md.append("")

    # === STOLEN BASES ===
    if any(p.get('sb_pick') for p in predictions):
        md.append("## Stolen Base Props (Team Over/Under)")
        md.append("")
        md.append("| Matchup | Pick | Prob | Confidence |")
        md.append("|---------|------|------|------------|")
        for p in predictions:
            if p.get('sb_pick', 'N/A') == 'N/A':
                continue
            matchup = f"{p['away_team']} @ {p['home_team']}"
            pick = p.get('sb_pick', 'N/A')
            prob = p.get('sb_prob', 0.5)
            conf = p.get('sb_confidence', 'N/A')
            md.append(f"| {matchup} | {pick} | {prob*100:.1f}% | {conf} |")
        md.append("")

    # === PITCHER K PROPS ===
    has_k = any(p.get('home_pitcher_k_pred') or p.get('away_pitcher_k_pred') for p in predictions)
    if has_k:
        md.append("## Pitcher Strikeout Props")
        md.append("")
        md.append("| Pitcher | Team | Predicted K | O/U 5.5 | O/U 6.5 |")
        md.append("|---------|------|-------------|---------|---------|")
        for p in predictions:
            for side in ['home', 'away']:
                k_pred = p.get(f'{side}_pitcher_k_pred')
                if k_pred is None:
                    continue
                name = p.get(f'{side}_pitcher_name', p.get(f'{side}_pitcher', 'TBA'))
                team = p[f'{side}_team']
                pick_55 = p.get(f'{side}_k_5.5_pick', 'N/A')
                pick_65 = p.get(f'{side}_k_6.5_pick', 'N/A')
                md.append(f"| {name} | {team} | {k_pred:.1f} K | {pick_55} | {pick_65} |")
        md.append("")

    # === BATTER PROPS ===
    has_batter = any(p.get('home_batter_preds') or p.get('away_batter_preds') for p in predictions)
    if has_batter:
        md.append("## Batter Props (Top Hitters)")
        md.append("")
        md.append("| Player | Team | Pred Hits/G | Pred HR/G |")
        md.append("|--------|------|-------------|-----------|")
        for p in predictions:
            for side in ['home', 'away']:
                batters = p.get(f'{side}_batter_preds', [])
                team = p[f'{side}_team']
                for b in batters:
                    md.append(f"| {b['name']} | {team} | {b['hits_pred']:.2f} | {b['hr_pred']:.3f} |")
        md.append("")

    # === FEATURED PICK ===
    best = actionable_ml[0] if actionable_ml else None
    if best:
        md.append(f"## Featured: {best['away_team']} @ {best['home_team']}")
        md.append("")
        md.append(f"**Moneyline: {best['ml_pick']}** ({best['ml_prob']*100:.1f}%, edge {edge_display(best['ml_edge'])})")

        if best.get('ou_predicted_total'):
            md.append(f"**Over/Under:** Predicted total {best['ou_predicted_total']:.1f} runs")
        if best.get('rl_pick') and best['rl_pick'] != 'PASS':
            md.append(f"**Run Line:** {best['rl_pick']} ({best['rl_covers_prob']*100:.1f}%)")
        if best.get('f5_pick') and best['f5_pick'] != 'PASS':
            md.append(f"**F5 Moneyline:** {best['f5_pick']} ({best['f5_prob']*100:.1f}%)")
        md.append("")

    # ãƒˆãƒ©ãƒƒã‚¯ãƒ¬ã‚³ãƒ¼ãƒ‰è¦ç´„
    track_record_path = PROJECT_DIR / "output" / "track_record_data.json"
    if track_record_path.exists():
        try:
            with open(track_record_path, 'r') as f:
                tr = json.load(f)
            sp = tr.get('strong_picks', {})
            md.append("## 2025 Backtested Track Record (STRONG Picks)")
            md.append("")
            md.append("| Market | Win Rate | ROI | Games |")
            md.append("|--------|----------|-----|-------|")
            for name in ['Moneyline', 'Run Line', 'Over/Under', 'F5 Moneyline']:
                s = sp.get(name)
                if s:
                    md.append(f"| {name} | {s['accuracy']:.1%} | {s['roi']:+.1f}% | {s['total']} |")
            c = tr.get('combined', {})
            if c:
                md.append(f"\n> Combined: **{c['accuracy']:.1%}** win rate, **{c['roi']:+.1f}%** ROI across {c['total']} picks")
            md.append("")
        except Exception:
            pass

    # ãƒ•ãƒƒã‚¿ãƒ¼
    md.append("---")
    md.append("")
    md.append(f"*{active_models} AI models. {len(predictions)} games. Real data. No gut feelings.*")
    md.append("*Not financial advice. Gamble responsibly.*")
    md.append("")
    md.append("**Subscribe** to get daily picks before first pitch.")

    content = "\n".join(md)
    print(f"  âœ“ English digest: {len(content)} characters")
    return content


def generate_japanese_digest(predictions, target_date, models_loaded):
    """note.comç”¨æ—¥æœ¬èªãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ â€” å…¨å¸‚å ´å¯¾å¿œ"""
    print("[7/9] Generating Japanese digest (note.com)...")

    if not predictions:
        return f"# Moneyball Dojo ãƒ‡ã‚¤ãƒªãƒ¼ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ â€” {target_date}\n\næœ¬æ—¥ã®è©¦åˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n"

    confidence_ja = {'STRONG': 'ğŸ”¥ å¼·æ°—', 'MODERATE': 'ğŸ‘ ä¸­ç¨‹åº¦', 'LEAN': 'â†’ å‚¾å‘', 'PASS': 'â¸ è¦‹é€ã‚Š', 'N/A': '-'}
    active_models = len(models_loaded)

    md = []
    md.append(f"# Moneyball Dojo ãƒ‡ã‚¤ãƒªãƒ¼ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ â€” {target_date}")
    md.append("")
    md.append(f"ã“ã‚“ã«ã¡ã¯ã€Moneyball Dojoã§ã™ã€‚æœ¬æ—¥ã¯{len(predictions)}è©¦åˆã‚’{active_models}ã¤ã®AIãƒ¢ãƒ‡ãƒ«ã§åˆ†æã—ã¾ã—ãŸã€‚")
    md.append("")

    # Spring Training banner
    is_spring_training = any(p.get('game_type') == 'S' for p in predictions)
    if is_spring_training:
        md.append("> **ã€æ˜¥å­£ã‚­ãƒ£ãƒ³ãƒ—æœŸé–“ä¸­ã€‘** æœ¬ãƒ¢ãƒ‡ãƒ«ã¯ãƒ¬ã‚®ãƒ¥ãƒ©ãƒ¼ã‚·ãƒ¼ã‚ºãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆ2022-2025å¹´ï¼‰ã§å­¦ç¿’ã—ã¦ã„ã¾ã™ã€‚")
        md.append("> æ˜¥å­£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯é€šå¸¸ã¨ç•°ãªã‚‹ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ»æŠ•æ‰‹èµ·ç”¨ã®ãŸã‚ã€äºˆæ¸¬ã¯å‚è€ƒå€¤ã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚")
        md.append("")

    md.append("---")
    md.append("")

    # === MONEYLINE ===
    md.append("## ãƒãƒãƒ¼ãƒ©ã‚¤ãƒ³äºˆæ¸¬")
    md.append("")
    md.append("| å¯¾æˆ¦ | äºˆæ¸¬ | å‹ç‡ | ã‚¨ãƒƒã‚¸ | ä¿¡é ¼åº¦ |")
    md.append("|------|------|------|--------|--------|")
    for p in predictions:
        matchup = f"{p['away_team']} @ {p['home_team']}"
        pick = p.get('ml_pick', 'N/A')
        prob = p.get('ml_prob', 0.5)
        e = p.get('ml_edge', 0)
        conf = confidence_ja.get(p.get('ml_confidence', 'N/A'), 'N/A')
        md.append(f"| {matchup} | {pick} | {prob*100:.1f}% | {edge_display(e)} | {conf} |")
    md.append("")

    # === OVER/UNDER ===
    if any(p.get('ou_predicted_total') for p in predictions):
        md.append("## åˆè¨ˆå¾—ç‚¹ (Over/Under)")
        md.append("")
        md.append("| å¯¾æˆ¦ | äºˆæƒ³åˆè¨ˆ | O/U 8.5 | ãƒãƒ¼ã‚¸ãƒ³ | ä¿¡é ¼åº¦ |")
        md.append("|------|---------|---------|---------|--------|")
        for p in predictions:
            if p.get('ou_predicted_total') is None:
                continue
            matchup = f"{p['away_team']} @ {p['home_team']}"
            total = p['ou_predicted_total']
            pick = p.get('ou_8.5_pick', 'N/A')
            margin = p.get('ou_8.5_margin', 0)
            conf = confidence_ja.get(p.get('ou_8.5_confidence', 'N/A'), '-')
            md.append(f"| {matchup} | {total:.1f} | {pick} | {margin:+.1f} | {conf} |")
        md.append("")

    # === RUN LINE ===
    rl_actionable_ja = [p for p in predictions if p.get('rl_confidence') in ('STRONG', 'MODERATE')]
    if rl_actionable_ja:
        md.append("## ãƒ©ãƒ³ãƒ©ã‚¤ãƒ³ (-1.5)")
        md.append("")
        md.append("| å¯¾æˆ¦ | äºˆæ¸¬ | ãƒ›ãƒ¼ãƒ ã‚«ãƒãƒ¼ç¢ºç‡ | ä¿¡é ¼åº¦ |")
        md.append("|------|------|-----------------|--------|")
        for p in rl_actionable_ja:
            matchup = f"{p['away_team']} @ {p['home_team']}"
            pick = p.get('rl_pick', 'N/A')
            prob = p.get('rl_covers_prob', 0.357)
            conf = confidence_ja.get(p.get('rl_confidence', 'N/A'), '-')
            md.append(f"| {matchup} | {pick} | {prob*100:.1f}% | {conf} |")
        md.append("")

    # === NRFI/YRFI ===
    if any(p.get('nrfi_pick') for p in predictions):
        md.append("## NRFI/YRFI (1å›è£è¡¨ã®ç„¡å¾—ç‚¹äºˆæ¸¬)")
        md.append("")
        md.append("| å¯¾æˆ¦ | äºˆæ¸¬ | ç¢ºç‡ | ä¿¡é ¼åº¦ |")
        md.append("|------|------|------|--------|")
        for p in predictions:
            if p.get('nrfi_pick', 'N/A') == 'N/A':
                continue
            matchup = f"{p['away_team']} @ {p['home_team']}"
            pick = p.get('nrfi_pick', 'N/A')
            prob = p.get('nrfi_prob', 0.5)
            conf = confidence_ja.get(p.get('nrfi_confidence', 'N/A'), '-')
            md.append(f"| {matchup} | {pick} | {prob*100:.1f}% | {conf} |")
        md.append("")

    # === PITCHER K PROPS ===
    has_k = any(p.get('home_pitcher_k_pred') or p.get('away_pitcher_k_pred') for p in predictions)
    if has_k:
        md.append("## æŠ•æ‰‹å¥ªä¸‰æŒ¯äºˆæ¸¬")
        md.append("")
        md.append("| æŠ•æ‰‹å | ãƒãƒ¼ãƒ  | äºˆæ¸¬K | O/U 5.5 | O/U 6.5 |")
        md.append("|--------|--------|-------|---------|---------|")
        for p in predictions:
            for side in ['home', 'away']:
                k_pred = p.get(f'{side}_pitcher_k_pred')
                if k_pred is None:
                    continue
                name = p.get(f'{side}_pitcher_name', p.get(f'{side}_pitcher', 'TBA'))
                team = p[f'{side}_team']
                pick_55 = p.get(f'{side}_k_5.5_pick', '-')
                pick_65 = p.get(f'{side}_k_6.5_pick', '-')
                md.append(f"| {name} | {team} | {k_pred:.1f} K | {pick_55} | {pick_65} |")
        md.append("")

    # === BATTER PROPS ===
    has_batter = any(p.get('home_batter_preds') or p.get('away_batter_preds') for p in predictions)
    if has_batter:
        md.append("## æ‰“è€…ãƒ—ãƒ­ãƒƒãƒ—ã‚¹ï¼ˆä¸»åŠ›æ‰“è€…ï¼‰")
        md.append("")
        md.append("| é¸æ‰‹å | ãƒãƒ¼ãƒ  | äºˆæ¸¬H/G | äºˆæ¸¬HR/G |")
        md.append("|--------|--------|---------|----------|")
        for p in predictions:
            for side in ['home', 'away']:
                batters = p.get(f'{side}_batter_preds', [])
                team = p[f'{side}_team']
                for b in batters:
                    md.append(f"| {b['name']} | {team} | {b['hits_pred']:.2f} | {b['hr_pred']:.3f} |")
        md.append("")

    # ãƒˆãƒ©ãƒƒã‚¯ãƒ¬ã‚³ãƒ¼ãƒ‰è¦ç´„
    track_record_path = PROJECT_DIR / "output" / "track_record_data.json"
    if track_record_path.exists():
        try:
            with open(track_record_path, 'r') as f:
                tr = json.load(f)
            sp = tr.get('strong_picks', {})
            name_ja = {'Moneyline': 'ML', 'Run Line': 'RL', 'Over/Under': 'O/U', 'F5 Moneyline': 'F5'}
            md.append("## 2025ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿç¸¾ï¼ˆSTRONGãƒ”ãƒƒã‚¯é™å®šï¼‰")
            md.append("")
            md.append("| ãƒãƒ¼ã‚±ãƒƒãƒˆ | å‹ç‡ | ROI | è©¦åˆæ•° |")
            md.append("|-----------|------|-----|--------|")
            for name in ['Moneyline', 'Run Line', 'Over/Under', 'F5 Moneyline']:
                s = sp.get(name)
                if s:
                    md.append(f"| {name_ja.get(name, name)} | {s['accuracy']:.1%} | {s['roi']:+.1f}% | {s['total']} |")
            c = tr.get('combined', {})
            if c:
                md.append(f"\n> å…¨ä½“: **{c['accuracy']:.1%}** å‹ç‡ã€**{c['roi']:+.1f}%** ROIï¼ˆ{c['total']}ãƒ”ãƒƒã‚¯ï¼‰")
            md.append("")
        except Exception:
            pass

    # ãƒ•ãƒƒã‚¿ãƒ¼
    md.append("---")
    md.append("")
    md.append(f"*æ±äº¬ã®AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒé–‹ç™ºã€‚{active_models}ãƒ¢ãƒ‡ãƒ« Ã— XGBoostã€‚ãƒ‡ãƒ¼ã‚¿ã§å‹è² ã™ã‚‹ã€‚*")
    md.append("*æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚è²¬ä»»ã‚ã‚‹ãƒ—ãƒ¬ã‚¤ã‚’ã€‚*")

    content = "\n".join(md)
    print(f"  âœ“ Japanese digest: {len(content)} characters")
    return content


def generate_twitter_post(predictions, target_date, models_loaded):
    """Twitter/XæŠ•ç¨¿ç”¨ã‚µãƒãƒªãƒ¼"""
    print("[8/9] Generating Twitter summary...")

    actionable = [p for p in predictions if p.get('ml_confidence') in ('STRONG', 'MODERATE')]
    active_models = len(models_loaded)

    lines = []
    lines.append(f"ğŸ¯ Moneyball Dojo AI Picks â€” {target_date}")
    lines.append(f"({active_models} models, {len(predictions)} games)")
    lines.append("")

    if not actionable:
        lines.append("No high-confidence picks today. Sometimes the best bet is no bet.")
    else:
        for p in actionable[:5]:
            emoji = "ğŸ”¥" if p.get('ml_confidence') == 'STRONG' else "ğŸ‘"
            lines.append(f"{emoji} {p['away_team']}@{p['home_team']}: {p.get('ml_pick', '?')} ({p.get('ml_prob', 0.5)*100:.0f}%)")

            # Over/Under
            if p.get('ou_predicted_total'):
                pick_85 = p.get('ou_8.5_pick', '')
                if pick_85 and pick_85 != 'PASS':
                    lines.append(f"   O/U: {p['ou_predicted_total']:.1f} ({pick_85} 8.5)")

    lines.append("")
    lines.append(f"Full analysis â†’ [Substack link]")
    lines.append("#MLB #SportsBetting #AIpicks #MoneyballDojo")

    content = "\n".join(lines)
    print(f"  âœ“ Twitter post: {len(content)} characters")
    return content


# ========================================================
# 7. ä¿å­˜
# ========================================================
def save_outputs(predictions, en_digest, ja_digest, twitter_post, target_date):
    """å…¨å‡ºåŠ›ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    print("[9/9] Saving outputs...")

    OUTPUT_DIR = PROJECT_DIR / "output" / target_date.replace("-", "")
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # CSVï¼ˆSheetsç”¨ï¼‰â€” ãƒã‚¹ãƒˆã•ã‚ŒãŸè¾æ›¸ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–
    csv_data = []
    for p in predictions:
        row = {}
        for k, v in p.items():
            if isinstance(v, (list, dict)):
                row[k] = json.dumps(v, ensure_ascii=False)
            elif isinstance(v, (np.integer,)):
                row[k] = int(v)
            elif isinstance(v, (np.floating,)):
                row[k] = float(v)
            else:
                row[k] = v
        csv_data.append(row)

    csv_path = OUTPUT_DIR / "predictions.csv"
    pd.DataFrame(csv_data).to_csv(csv_path, index=False)
    print(f"  âœ“ CSV â†’ {csv_path}")

    # è‹±èªDigest
    en_path = OUTPUT_DIR / f"digest_EN_{target_date}.md"
    en_path.write_text(en_digest, encoding='utf-8')
    print(f"  âœ“ English Digest â†’ {en_path}")

    # æ—¥æœ¬èªDigest
    ja_path = OUTPUT_DIR / f"digest_JA_{target_date}.md"
    ja_path.write_text(ja_digest, encoding='utf-8')
    print(f"  âœ“ Japanese Digest â†’ {ja_path}")

    # TwitteræŠ•ç¨¿
    tw_path = OUTPUT_DIR / f"twitter_{target_date}.txt"
    tw_path.write_text(twitter_post, encoding='utf-8')
    print(f"  âœ“ Twitter â†’ {tw_path}")

    # JSONï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰
    def convert_numpy(obj):
        if isinstance(obj, (np.integer,)):
            return int(obj)
        elif isinstance(obj, (np.floating,)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return obj

    clean_predictions = []
    for p in predictions:
        clean_predictions.append({k: convert_numpy(v) for k, v in p.items()})

    json_path = OUTPUT_DIR / f"predictions_{target_date}.json"
    json_path.write_text(json.dumps(clean_predictions, indent=2, ensure_ascii=False), encoding='utf-8')
    print(f"  âœ“ JSON â†’ {json_path}")

    # === output/latest/ â€” always overwrite with the most recent run ===
    LATEST_DIR = PROJECT_DIR / "output" / "latest"
    if LATEST_DIR.exists():
        import shutil
        shutil.rmtree(LATEST_DIR)
    LATEST_DIR.mkdir(parents=True, exist_ok=True)

    (LATEST_DIR / "POST_TO_SUBSTACK.md").write_text(en_digest, encoding='utf-8')
    (LATEST_DIR / "POST_TO_NOTE.md").write_text(ja_digest, encoding='utf-8')
    (LATEST_DIR / "POST_TO_X.txt").write_text(twitter_post, encoding='utf-8')
    pd.DataFrame(csv_data).to_csv(LATEST_DIR / "predictions.csv", index=False)
    (LATEST_DIR / "predictions.json").write_text(
        json.dumps(clean_predictions, indent=2, ensure_ascii=False), encoding='utf-8')
    (LATEST_DIR / "README.txt").write_text(
        f"Moneyball Dojo - Latest Predictions ({target_date})\n"
        f"=================================================\n\n"
        f"POST_TO_SUBSTACK.md  -> Substack (English)\n"
        f"POST_TO_NOTE.md      -> note.com (Japanese)\n"
        f"POST_TO_X.txt        -> Twitter/X\n\n"
        f"predictions.csv      -> Google Sheets\n"
        f"predictions.json     -> Full data (API/archive)\n\n"
        f"Generated by: python3 run_daily.py\n",
        encoding='utf-8')
    print(f"  âœ“ latest/ â†’ {LATEST_DIR}/")

    return OUTPUT_DIR


def upload_to_sheets(predictions, target_date, model_version="v3"):
    """
    Google Sheets v2 ã‚¹ã‚­ãƒ¼ãƒã«åŸºã¥ãäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ append ã™ã‚‹ã€‚
    èªè¨¼: credentials.json ã¾ãŸã¯ GOOGLE_SHEETS_CREDENTIALS ç’°å¢ƒå¤‰æ•°
    å¯¾è±¡: GOOGLE_SHEETS_ID ç’°å¢ƒå¤‰æ•° or SPREADSHEET_NAME
    """
    if not SHEETS_AVAILABLE:
        print("  âš  gspreadæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â†’ pip install gspread google-auth")
        return False

    # èªè¨¼
    gc = None
    try:
        # 1) ç’°å¢ƒå¤‰æ•°ã‹ã‚‰JSONèªè¨¼æƒ…å ±ï¼ˆGitHub Actionsç”¨ï¼‰
        creds_json = os.environ.get('GOOGLE_SHEETS_CREDENTIALS')
        if creds_json:
            import json as _json
            creds_dict = _json.loads(creds_json)
            credentials = ServiceAccountCredentials.from_service_account_info(
                creds_dict,
                scopes=['https://www.googleapis.com/auth/spreadsheets'],
            )
            gc = gspread.authorize(credentials)
        # 2) credentials.json ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç”¨ï¼‰
        elif CREDENTIALS_PATH.exists():
            gc = gspread.service_account(filename=str(CREDENTIALS_PATH))
        else:
            print("  âš  èªè¨¼æƒ…å ±ãªã—ï¼ˆcredentials.json / GOOGLE_SHEETS_CREDENTIALSï¼‰â†’ Sheetsé€£æºã‚¹ã‚­ãƒƒãƒ—")
            return False
    except Exception as e:
        print(f"  âš  Sheetsèªè¨¼å¤±æ•—: {e}")
        return False

    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã
    try:
        sheet_id = os.environ.get('GOOGLE_SHEETS_ID')
        if sheet_id:
            sh = gc.open_by_key(sheet_id)
        else:
            sh = gc.open(SPREADSHEET_NAME)
    except Exception as e:
        print(f"  âš  Spreadsheet open failed: {e}")
        return False

    now_iso = datetime.utcnow().isoformat() + "Z"
    errors = []

    # --- Sheet: Daily Predictions (ãƒ¡ã‚¤ãƒ³ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿) ---
    try:
        ws = _get_or_create_worksheet(sh, 'Daily Predictions')
        rows = []
        for p in predictions:
            rows.append([
                target_date,
                str(p.get('game_id', '')),
                str(p.get('away_team', '')),
                str(p.get('home_team', '')),
                str(p.get('away_pitcher', 'TBA')),
                str(p.get('home_pitcher', 'TBA')),
                str(round(float(p.get('ml_prob', 0)), 4)),
                str(p.get('ml_pick', '')),
                str(round(float(p.get('ml_edge', 0)), 4)),
                str(p.get('ml_confidence', '')),
                str(p.get('ou_predicted_total', '')),
                str(p.get('rl_pick', '')),
                str(p.get('rl_confidence', '')),
                str(p.get('f5_pick', '')),
                str(p.get('f5_confidence', '')),
                str(p.get('nrfi_pick', '')),
                str(p.get('nrfi_confidence', '')),
                str(p.get('sb_pick', '')),
                now_iso,
            ])
        _batch_append_with_retry(ws, rows)
        print(f"  âœ“ Daily Predictions â†’ {len(rows)} rows")
    except Exception as e:
        errors.append(f"Daily Predictions: {e}")

    # --- Sheet: predictions (v2 ã‚¹ã‚­ãƒ¼ãƒ: append-only event log) ---
    try:
        ws_pred = _get_or_create_worksheet(sh, 'predictions')
        pred_rows = []
        for p in predictions:
            pred_rows.append([
                str(p.get('game_id', '')),
                f"{model_version}_{target_date.replace('-', '_')}",
                str(round(float(p.get('ml_prob', 0)), 4)),
                str(p.get('ou_predicted_total', '')),
                str(round(float(p.get('ml_edge', 0)), 4)),
                str(p.get('ml_confidence', '')),
                str(p.get('ml_pick', '')),
                f"Edge={p.get('ml_edge', 0)*100:+.1f}%",
                now_iso,
            ])
        _batch_append_with_retry(ws_pred, pred_rows)
        print(f"  âœ“ predictions (v2 log) â†’ {len(pred_rows)} rows")
    except Exception as e:
        errors.append(f"predictions: {e}")

    if errors:
        for err in errors:
            print(f"  âš  Sheets error: {err}")
        return False

    return True


def _get_or_create_worksheet(sh, name):
    """ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’å–å¾—ã€‚ãªã‘ã‚Œã°ä½œæˆã™ã‚‹ã€‚"""
    try:
        return sh.worksheet(name)
    except gspread.exceptions.WorksheetNotFound:
        return sh.add_worksheet(title=name, rows=1000, cols=26)


def _batch_append_with_retry(ws, rows, max_retries=MAX_RETRIES):
    """gspread batch append with retry logic."""
    for attempt in range(max_retries):
        try:
            ws.append_rows(rows, value_input_option='USER_ENTERED')
            return
        except Exception as e:
            if attempt < max_retries - 1:
                delay = RETRY_DELAYS[attempt]
                logger.warning(f"Sheets append failed (attempt {attempt+1}): {e}. Retrying in {delay}s...")
                time.sleep(delay)
            else:
                raise


# ========================================================
# ã‚¨ãƒ©ãƒ¼é€šçŸ¥
# ========================================================
def _notify_error(step_name: str, error: Exception, target_date: str):
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼ã‚’ Slack / GitHub Issues ã«é€šçŸ¥ã™ã‚‹ã€‚"""
    error_msg = f"[{step_name}] {type(error).__name__}: {error}"
    logger.error(error_msg)
    logger.error(traceback.format_exc())

    # Slacké€šçŸ¥ï¼ˆç’°å¢ƒå¤‰æ•°ã‚ã‚Œã°ï¼‰
    slack_webhook = os.environ.get('SLACK_WEBHOOK')
    if slack_webhook:
        try:
            import requests
            payload = {
                "text": f"ğŸš¨ Moneyball Dojo Pipeline Error â€” {target_date}\n"
                        f"Step: {step_name}\n"
                        f"Error: {error_msg}\n"
                        f"```{traceback.format_exc()[-500:]}```"
            }
            for attempt in range(MAX_RETRIES):
                try:
                    resp = requests.post(slack_webhook, json=payload, timeout=10)
                    if resp.status_code == 200:
                        logger.info("Slack notification sent")
                        break
                except Exception:
                    if attempt < MAX_RETRIES - 1:
                        time.sleep(RETRY_DELAYS[attempt])
        except ImportError:
            pass

    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
    error_dir = PROJECT_DIR / "output" / target_date.replace("-", "")
    error_dir.mkdir(parents=True, exist_ok=True)
    error_path = error_dir / "pipeline_errors.log"
    with open(error_path, 'a', encoding='utf-8') as f:
        f.write(f"\n{'='*60}\n")
        f.write(f"Time: {datetime.utcnow().isoformat()}Z\n")
        f.write(f"Step: {step_name}\n")
        f.write(f"Error: {error_msg}\n")
        f.write(traceback.format_exc())


def _run_step_with_retry(step_name, func, *args, max_retries=MAX_RETRIES, **kwargs):
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ãƒ†ãƒƒãƒ—ã‚’ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§å®Ÿè¡Œã™ã‚‹ã€‚"""
    last_error = None
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            last_error = e
            if attempt < max_retries - 1:
                delay = RETRY_DELAYS[attempt]
                logger.warning(f"[{step_name}] failed (attempt {attempt+1}): {e}. Retrying in {delay}s...")
                time.sleep(delay)
            else:
                logger.error(f"[{step_name}] failed after {max_retries} attempts")
    raise last_error


# ========================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ========================================================
def main():
    target_date = sys.argv[1] if len(sys.argv) > 1 else datetime.now().strftime("%Y-%m-%d")
    pipeline_errors = []

    print("=" * 70)
    print("MONEYBALL DOJO â€” DAILY PREDICTION PIPELINE v4 (FULL AUTOMATION)")
    print(f"Date: {target_date}")
    print("=" * 70)
    print()

    # 1. å…¨ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    models = load_all_models()
    print()

    # 2. å½“æ—¥ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—
    games = get_todays_schedule(target_date)
    print()

    if not games:
        print("âŒ No games found. Exiting.")
        return

    # 3. éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    games_df, team_stats, latest_year, pitcher_stats, latest_pitcher_year, batter_stats, latest_batter_year = load_historical_data()
    print()

    # 4. äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤º
    print("[4/9] Computing team metrics & rolling stats...")
    print(f"  âœ“ Using {latest_year} as reference season")
    print()

    # 5. å…¨ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
    predictions = generate_all_predictions(
        games, models, games_df, team_stats, latest_year,
        pitcher_stats, latest_pitcher_year,
        batter_stats, latest_batter_year
    )
    print()

    if not predictions:
        print("âŒ No predictions generated. Exiting.")
        return

    # 6. è‹±èªDigestï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç‰ˆ â€” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    en_digest = generate_english_digest(predictions, target_date, models)
    print()

    # 7. æ—¥æœ¬èªDigestï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç‰ˆ â€” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    ja_digest = generate_japanese_digest(predictions, target_date, models)
    print()

    # 8. TwitteræŠ•ç¨¿
    twitter_post = generate_twitter_post(predictions, target_date, models)
    print()

    # ========================================================
    # [NEW] Anthropic API ã«ã‚ˆã‚‹è¨˜äº‹ç”Ÿæˆï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç‰ˆã‚’ä¸Šæ›¸ãï¼‰
    # ========================================================
    if ARTICLE_GEN_AVAILABLE:
        print("[API] Generating AI-powered articles via Anthropic API...")
        try:
            generator = ArticleGenerator()
            if generator.api_available:
                api_en, api_ja = _run_step_with_retry(
                    "Anthropic API Article Generation",
                    generator.generate_daily_digest,
                    predictions, target_date, len(models),
                )
                if api_en:
                    en_digest = api_en
                    print(f"  âœ“ API English digest: {len(en_digest)} characters")
                if api_ja:
                    ja_digest = api_ja
                    print(f"  âœ“ API Japanese digest: {len(ja_digest)} characters")
            else:
                print("  âš  Anthropic API key not set â€” using template digests")
        except Exception as e:
            pipeline_errors.append(("Anthropic API", e))
            _notify_error("Anthropic API Article Generation", e, target_date)
            print(f"  âš  API article generation failed: {e} â€” using template fallback")
    else:
        print("[API] article_generator_template not available â€” using template digests")
    print()

    # 9. ä¿å­˜
    output_dir = save_outputs(predictions, en_digest, ja_digest, twitter_post, target_date)
    print()

    # ========================================================
    # [NEW] Google Sheets v2 ã‚¹ã‚­ãƒ¼ãƒè‡ªå‹•æ›¸ãè¾¼ã¿
    # ========================================================
    print("[SHEETS] Uploading to Google Sheets (v2 schema)...")
    try:
        sheets_ok = _run_step_with_retry(
            "Google Sheets Upload",
            upload_to_sheets,
            predictions, target_date,
            max_retries=MAX_RETRIES,
        )
        if not sheets_ok:
            print("  âš  Sheets upload skipped (no credentials)")
    except Exception as e:
        pipeline_errors.append(("Google Sheets", e))
        _notify_error("Google Sheets Upload", e, target_date)
        print(f"  âš  Sheets upload failed: {e}")
    print()

    # ========================================================
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚µãƒãƒªãƒ¼
    # ========================================================
    print("=" * 70)
    if pipeline_errors:
        print(f"âš ï¸  PIPELINE COMPLETE WITH {len(pipeline_errors)} ERROR(S)")
        for step, err in pipeline_errors:
            print(f"   âŒ {step}: {err}")
    else:
        print("âœ… DAILY PIPELINE v4 COMPLETE â€” FULL AUTOMATION")
    print(f"   Models used: {', '.join(models.keys())}")
    print(f"   Games analyzed: {len(predictions)}")
    print(f"   All outputs saved to: {output_dir}/")
    print()

    if not pipeline_errors:
        print("ğŸ¤– FULLY AUTOMATED â€” No manual steps needed!")
        print("   Articles generated â†’ Ready for Substack / note.com")
        print("   Sheets updated â†’ Google Sheets synced")
    else:
        print("ğŸ“‹ FALLBACK STEPS:")
        print(f"   1. Open {output_dir}/digest_EN_{target_date}.md â†’ Substack")
        print(f"   2. Open {output_dir}/digest_JA_{target_date}.md â†’ note.com")
        print(f"   3. Open {output_dir}/twitter_{target_date}.txt â†’ Twitter/X")
    print("=" * 70)


if __name__ == '__main__':
    main()

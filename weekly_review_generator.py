#!/usr/bin/env python3
"""
Moneyball Dojo â€” Weekly Review Generator
=========================================
éå»7æ—¥é–“ã®äºˆæ¸¬ vs å®Ÿç¸¾ã‚’é›†è¨ˆã—ã€EN/JA ã®æŒ¯ã‚Šè¿”ã‚Šãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

å‡ºåŠ›:
  - output/weekly/review_EN_{end_date}.md
  - output/weekly/review_JA_{end_date}.md
  - output/weekly/review_data_{end_date}.json

ä½¿ã„æ–¹:
  python3 weekly_review_generator.py              # ç›´è¿‘7æ—¥é–“
  python3 weekly_review_generator.py 2026-03-31   # æŒ‡å®šæ—¥ã‚’çµ‚äº†æ—¥ã¨ã—ã¦7æ—¥åˆ†
"""

import json
import os
import sys
import time
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

PROJECT_DIR = Path(__file__).parent
OUTPUT_DIR = PROJECT_DIR / "output"
WEEKLY_DIR = OUTPUT_DIR / "weekly"
DATA_DIR = PROJECT_DIR / "data"
GAMES_PATH = DATA_DIR / "games_2022_2025.csv"


def calculate_roi(wins, total, odds=-110):
    """å‹æ•—æ•°ã‹ã‚‰ROIã‚’è¨ˆç®—ï¼ˆ-110ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã‚¸ãƒ¥ãƒ¼ã‚¹å‰æï¼‰"""
    if total == 0:
        return 0.0
    losses = total - wins
    payout_per_win = 100 / abs(odds) if odds < 0 else odds / 100
    profit = wins * payout_per_win - losses * 1.0
    return profit / total * 100


def load_week_predictions(end_date, days=7):
    """éå»Næ—¥é–“ã®äºˆæ¸¬CSVã‚’çµåˆã—ã¦è¿”ã™"""
    frames = []
    for i in range(days):
        d = end_date - timedelta(days=i)
        dated_dir = OUTPUT_DIR / d.strftime('%Y%m%d')
        csv_path = dated_dir / "predictions.csv"
        if csv_path.exists():
            df = pd.read_csv(csv_path)
            if 'date' not in df.columns:
                df['date'] = d.strftime('%Y-%m-%d')
            frames.append(df)

    if not frames:
        return pd.DataFrame()
    return pd.concat(frames, ignore_index=True)


def load_results(start_date, end_date):
    """æœŸé–“å†…ã®ã‚²ãƒ¼ãƒ çµæœã‚’èª­ã¿è¾¼ã‚€"""
    if not GAMES_PATH.exists():
        return pd.DataFrame()

    df = pd.read_csv(GAMES_PATH)
    df['date'] = pd.to_datetime(df['date'])
    mask = (df['date'] >= pd.Timestamp(start_date)) & (df['date'] <= pd.Timestamp(end_date))
    return df[mask].copy()


def evaluate_picks(predictions, results):
    """äºˆæ¸¬ã¨çµæœã‚’çªãåˆã‚ã›ã¦å‹æ•—ã‚’åˆ¤å®šã™ã‚‹"""
    if predictions.empty or results.empty:
        return pd.DataFrame()

    predictions = predictions.copy()
    results = results.copy()

    predictions['game_id'] = predictions['game_id'].astype(int)
    results['game_id'] = results['game_id'].astype(int)

    merged = predictions.merge(
        results[['game_id', 'home_score', 'away_score', 'home_win']],
        on='game_id',
        how='inner'
    )

    if merged.empty:
        return merged

    # Moneyline correctness
    merged['ml_correct'] = 0
    home_pick = merged['ml_pick'] == 'HOME'
    away_pick = merged['ml_pick'] == 'AWAY'
    merged.loc[home_pick & (merged['home_win'] == 1), 'ml_correct'] = 1
    merged.loc[away_pick & (merged['home_win'] == 0), 'ml_correct'] = 1

    # Run line correctness (HOME -1.5 / AWAY +1.5)
    margin = merged['home_score'] - merged['away_score']
    merged['rl_correct'] = 0
    rl_home = merged['rl_pick'] == 'HOME -1.5'
    rl_away = merged['rl_pick'] == 'AWAY +1.5'
    merged.loc[rl_home & (margin >= 2), 'rl_correct'] = 1
    merged.loc[rl_away & (margin <= 1), 'rl_correct'] = 1

    # F5 correctness
    merged['f5_correct'] = 0
    f5_home = merged['f5_pick'] == 'HOME'
    f5_away = merged['f5_pick'] == 'AWAY'
    merged.loc[f5_home & (merged['home_win'] == 1), 'f5_correct'] = 1
    merged.loc[f5_away & (merged['home_win'] == 0), 'f5_correct'] = 1

    # NRFI correctness
    total_1st = merged['home_score'].clip(upper=1) + merged['away_score'].clip(upper=1)
    merged['nrfi_correct'] = 0
    # NOTE: NRFI accuracy requires inning-level data; approximate via game result is rough
    # Full accuracy requires nrfi_data CSV â€” skip if unavailable

    return merged


def compute_tier_stats(evaluated, model_prefix, confidence_col=None):
    """ä¿¡é ¼åº¦ãƒ†ã‚£ã‚¢åˆ¥ã®å‹æ•—çµ±è¨ˆã‚’è¨ˆç®—"""
    if evaluated.empty:
        return {}

    correct_col = f'{model_prefix}_correct'
    conf_col = confidence_col or f'{model_prefix}_confidence'
    pick_col = f'{model_prefix}_pick'

    if correct_col not in evaluated.columns or conf_col not in evaluated.columns:
        return {}

    # Exclude PASS/N/A picks
    active = evaluated[~evaluated[pick_col].isin(['PASS', 'N/A', ''])]
    active = active.dropna(subset=[pick_col])

    stats = {}
    for tier in ['STRONG', 'MODERATE', 'LEAN']:
        tier_df = active[active[conf_col] == tier]
        if tier_df.empty:
            continue
        wins = int(tier_df[correct_col].sum())
        total = len(tier_df)
        stats[tier] = {
            'wins': wins,
            'losses': total - wins,
            'total': total,
            'accuracy': round(wins / total, 4) if total > 0 else 0,
            'roi': round(calculate_roi(wins, total), 2),
        }

    # All tiers combined
    all_active = active[active[conf_col].isin(['STRONG', 'MODERATE', 'LEAN'])]
    if not all_active.empty:
        w = int(all_active[correct_col].sum())
        t = len(all_active)
        stats['ALL'] = {
            'wins': w,
            'losses': t - w,
            'total': t,
            'accuracy': round(w / t, 4) if t > 0 else 0,
            'roi': round(calculate_roi(w, t), 2),
        }

    return stats


def find_notable_picks(evaluated, n=3):
    """ãƒ™ã‚¹ãƒˆãƒ”ãƒƒã‚¯ï¼ˆçš„ä¸­ + é«˜ã‚¨ãƒƒã‚¸ï¼‰ã¨ãƒ¯ãƒ¼ã‚¹ãƒˆãƒ”ãƒƒã‚¯ï¼ˆå¤–ã‚Œ + é«˜ã‚¨ãƒƒã‚¸ï¼‰ã‚’è¿”ã™"""
    if evaluated.empty:
        return [], []

    active = evaluated[evaluated['ml_pick'].isin(['HOME', 'AWAY'])].copy()
    if active.empty:
        return [], []

    active['ml_edge_f'] = pd.to_numeric(active['ml_edge'], errors='coerce').fillna(0)

    correct = active[active['ml_correct'] == 1].nlargest(n, 'ml_edge_f')
    wrong = active[active['ml_correct'] == 0].nlargest(n, 'ml_edge_f')

    def pick_to_dict(row):
        return {
            'matchup': f"{row['away_team']} @ {row['home_team']}",
            'date': str(row.get('date', '')).split(' ')[0].split('T')[0],
            'pick': row['ml_pick'],
            'prob': float(row.get('ml_prob', 0)),
            'edge': float(row.get('ml_edge', 0)),
            'confidence': row.get('ml_confidence', ''),
            'score': f"{int(row.get('away_score', 0))}-{int(row.get('home_score', 0))}",
            'correct': int(row.get('ml_correct', 0)),
        }

    best = [pick_to_dict(r) for _, r in correct.iterrows()]
    worst = [pick_to_dict(r) for _, r in wrong.iterrows()]
    return best, worst


def generate_english_review(stats, best_picks, worst_picks, evaluated, start_str, end_str, days_with_data):
    """è‹±èªç‰ˆé€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆ"""
    md = []
    md.append(f"# Moneyball Dojo Weekly Review â€” {start_str} to {end_str}")
    md.append("")
    md.append(f"*{days_with_data} days of predictions evaluated. Here's how the AI performed.*")
    md.append("")
    md.append("---")
    md.append("")

    # Overall Summary
    ml_all = stats.get('ml', {}).get('ALL', {})
    ml_strong = stats.get('ml', {}).get('STRONG', {})

    if ml_all:
        md.append("## Overall Performance")
        md.append("")
        md.append("| Metric | All Picks | STRONG Only |")
        md.append("|--------|-----------|-------------|")
        md.append(f"| Record | {ml_all['wins']}W-{ml_all['losses']}L | "
                   f"{ml_strong.get('wins', 0)}W-{ml_strong.get('losses', 0)}L |")
        md.append(f"| Accuracy | {ml_all['accuracy']*100:.1f}% | "
                   f"{ml_strong.get('accuracy', 0)*100:.1f}% |")
        md.append(f"| ROI | {ml_all['roi']:+.1f}% | "
                   f"{ml_strong.get('roi', 0):+.1f}% |")
        md.append(f"| Total Games | {ml_all['total']} | "
                   f"{ml_strong.get('total', 0)} |")
        md.append("")

    # Per-model breakdown
    md.append("## Model Breakdown (STRONG Picks)")
    md.append("")
    md.append("| Model | Record | Accuracy | ROI |")
    md.append("|-------|--------|----------|-----|")
    for model, label in [('ml', 'Moneyline'), ('rl', 'Run Line'), ('f5', 'F5 Moneyline')]:
        s = stats.get(model, {}).get('STRONG', {})
        if s:
            md.append(f"| {label} | {s['wins']}W-{s['losses']}L | "
                       f"{s['accuracy']*100:.1f}% | {s['roi']:+.1f}% |")
    md.append("")

    # Best picks
    if best_picks:
        md.append("## Best Picks of the Week")
        md.append("")
        for p in best_picks:
            md.append(f"- **{p['matchup']}** ({p['date']}) â€” "
                       f"{p['pick']} at {p['prob']*100:.0f}% (edge {p['edge']*100:+.1f}%) "
                       f"| Final: {p['score']}")
        md.append("")

    # Worst picks
    if worst_picks:
        md.append("## Biggest Misses")
        md.append("")
        for p in worst_picks:
            md.append(f"- **{p['matchup']}** ({p['date']}) â€” "
                       f"{p['pick']} at {p['prob']*100:.0f}% (edge {p['edge']*100:+.1f}%) "
                       f"| Final: {p['score']}")
        md.append("")

    # Confidence tier table
    md.append("## Accuracy by Confidence Tier")
    md.append("")
    md.append("| Tier | Record | Accuracy | ROI |")
    md.append("|------|--------|----------|-----|")
    for tier in ['STRONG', 'MODERATE', 'LEAN']:
        s = stats.get('ml', {}).get(tier, {})
        if s:
            md.append(f"| {tier} | {s['wins']}W-{s['losses']}L | "
                       f"{s['accuracy']*100:.1f}% | {s['roi']:+.1f}% |")
    md.append("")

    md.append("---")
    md.append("")
    md.append("*9 AI models. Real data. Full transparency.*")
    md.append("*Not financial advice. Gamble responsibly.*")
    md.append("")

    return "\n".join(md)


def generate_japanese_review(stats, best_picks, worst_picks, evaluated, start_str, end_str, days_with_data):
    """æ—¥æœ¬èªç‰ˆé€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆ"""
    md = []
    md.append(f"# Moneyball Dojo é€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ â€” {start_str} ã€œ {end_str}")
    md.append("")
    md.append(f"*{days_with_data}æ—¥é–“ã®AIäºˆæ¸¬ã‚’æŒ¯ã‚Šè¿”ã‚Šã¾ã™ã€‚*")
    md.append("")
    md.append("---")
    md.append("")

    ml_all = stats.get('ml', {}).get('ALL', {})
    ml_strong = stats.get('ml', {}).get('STRONG', {})

    if ml_all:
        md.append("## å…¨ä½“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
        md.append("")
        md.append("| æŒ‡æ¨™ | å…¨ãƒ”ãƒƒã‚¯ | STRONG ã®ã¿ |")
        md.append("|------|---------|------------|")
        md.append(f"| æˆ¦ç¸¾ | {ml_all['wins']}å‹{ml_all['losses']}æ•— | "
                   f"{ml_strong.get('wins', 0)}å‹{ml_strong.get('losses', 0)}æ•— |")
        md.append(f"| çš„ä¸­ç‡ | {ml_all['accuracy']*100:.1f}% | "
                   f"{ml_strong.get('accuracy', 0)*100:.1f}% |")
        md.append(f"| ROI | {ml_all['roi']:+.1f}% | "
                   f"{ml_strong.get('roi', 0):+.1f}% |")
        md.append(f"| è©¦åˆæ•° | {ml_all['total']} | "
                   f"{ml_strong.get('total', 0)} |")
        md.append("")

    # Per-model
    md.append("## ãƒ¢ãƒ‡ãƒ«åˆ¥æˆç¸¾ï¼ˆSTRONG ãƒ”ãƒƒã‚¯ï¼‰")
    md.append("")
    md.append("| ãƒ¢ãƒ‡ãƒ« | æˆ¦ç¸¾ | çš„ä¸­ç‡ | ROI |")
    md.append("|--------|------|--------|-----|")
    for model, label in [('ml', 'ãƒãƒãƒ¼ãƒ©ã‚¤ãƒ³'), ('rl', 'ãƒ©ãƒ³ãƒ©ã‚¤ãƒ³'), ('f5', 'F5ãƒãƒãƒ¼ãƒ©ã‚¤ãƒ³')]:
        s = stats.get(model, {}).get('STRONG', {})
        if s:
            md.append(f"| {label} | {s['wins']}å‹{s['losses']}æ•— | "
                       f"{s['accuracy']*100:.1f}% | {s['roi']:+.1f}% |")
    md.append("")

    # Best
    if best_picks:
        md.append("## ä»Šé€±ã®ãƒ™ã‚¹ãƒˆãƒ”ãƒƒã‚¯")
        md.append("")
        for p in best_picks:
            md.append(f"- **{p['matchup']}** ({p['date']}) â€” "
                       f"{p['pick']} {p['prob']*100:.0f}% (ã‚¨ãƒƒã‚¸ {p['edge']*100:+.1f}%) "
                       f"| çµæœ: {p['score']}")
        md.append("")

    # Worst
    if worst_picks:
        md.append("## ä»Šé€±ã®å¤–ã‚Œãƒ”ãƒƒã‚¯")
        md.append("")
        for p in worst_picks:
            md.append(f"- **{p['matchup']}** ({p['date']}) â€” "
                       f"{p['pick']} {p['prob']*100:.0f}% (ã‚¨ãƒƒã‚¸ {p['edge']*100:+.1f}%) "
                       f"| çµæœ: {p['score']}")
        md.append("")

    # Tiers
    conf_ja = {'STRONG': 'å¼·æ°—', 'MODERATE': 'ä¸­ç¨‹åº¦', 'LEAN': 'å‚¾å‘'}
    md.append("## ä¿¡é ¼åº¦ãƒ†ã‚£ã‚¢åˆ¥ã®çš„ä¸­ç‡")
    md.append("")
    md.append("| ãƒ†ã‚£ã‚¢ | æˆ¦ç¸¾ | çš„ä¸­ç‡ | ROI |")
    md.append("|--------|------|--------|-----|")
    for tier in ['STRONG', 'MODERATE', 'LEAN']:
        s = stats.get('ml', {}).get(tier, {})
        if s:
            md.append(f"| {conf_ja.get(tier, tier)} | "
                       f"{s['wins']}å‹{s['losses']}æ•— | "
                       f"{s['accuracy']*100:.1f}% | {s['roi']:+.1f}% |")
    md.append("")

    md.append("---")
    md.append("")
    md.append("*æ±äº¬ã®AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒé–‹ç™ºã€‚9ãƒ¢ãƒ‡ãƒ« Ã— XGBoostã€‚ãƒ‡ãƒ¼ã‚¿ã§å‹è² ã™ã‚‹ã€‚*")
    md.append("*æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚è²¬ä»»ã‚ã‚‹ãƒ—ãƒ¬ã‚¤ã‚’ã€‚*")
    md.append("")

    return "\n".join(md)


MAX_RETRIES = 3
RETRY_DELAYS = [2, 4, 8]


def _slack_post(webhook_url, payload):
    """Slack webhookã«POSTã™ã‚‹ã€‚ãƒªãƒˆãƒ©ã‚¤ä»˜ãã€‚"""
    try:
        import requests
    except ImportError:
        return False
    for attempt in range(MAX_RETRIES):
        try:
            resp = requests.post(webhook_url, json=payload, timeout=10)
            if resp.status_code == 200:
                return True
        except Exception:
            pass
        if attempt < MAX_RETRIES - 1:
            time.sleep(RETRY_DELAYS[attempt])
    return False


def notify_review(en_review, ja_review, stats, start_str, end_str):
    """é€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†æ™‚ã«Slackã¸ãƒ•ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é€ä¿¡ã™ã‚‹ã€‚"""
    slack_webhook = os.environ.get('SLACK_WEBHOOK')
    if not slack_webhook:
        print("  âš  SLACK_WEBHOOK not set â€” skipping Slack notification")
        return

    # --- Message 1: ã‚µãƒãƒªãƒ¼ ---
    ml_all = stats.get('ml', {}).get('ALL', {})
    ml_strong = stats.get('ml', {}).get('STRONG', {})
    summary_lines = [
        f"*ğŸ“Š Moneyball Dojo Weekly Review â€” {start_str} ã€œ {end_str}*",
        "",
    ]
    if ml_all:
        summary_lines.append(f"å…¨ãƒ”ãƒƒã‚¯: {ml_all['wins']}W-{ml_all['losses']}L "
                             f"({ml_all['accuracy']*100:.1f}%, ROI {ml_all['roi']:+.1f}%)")
    if ml_strong:
        summary_lines.append(f"STRONG: {ml_strong['wins']}W-{ml_strong['losses']}L "
                             f"({ml_strong['accuracy']*100:.1f}%, ROI {ml_strong['roi']:+.1f}%)")
    if not ml_all:
        summary_lines.append("(ãƒ‡ãƒ¼ã‚¿ãªã— â€” äºˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒæœªç”Ÿæˆ)")

    _slack_post(slack_webhook, {"text": "\n".join(summary_lines)})

    # --- Message 2: EN review (for Substack) ---
    en_trimmed = en_review[:3900]
    if len(en_review) > 3900:
        en_trimmed += "\n\n... (truncated, full version in output/weekly/)"
    _slack_post(slack_webhook, {
        "text": f"*--- WEEKLY REVIEW EN (copy below) ---*\n```{en_trimmed}```"
    })

    # --- Message 3: JA review (for note.com) ---
    ja_trimmed = ja_review[:3900]
    if len(ja_review) > 3900:
        ja_trimmed += "\n\n... (truncated, full version in output/weekly/)"
    _slack_post(slack_webhook, {
        "text": f"*--- WEEKLY REVIEW JA (copy below) ---*\n```{ja_trimmed}```"
    })

    print("  âœ“ Slack notifications sent (3 messages)")


def main():
    print("=" * 60)
    print("Moneyball Dojo â€” Weekly Review Generator")
    print("=" * 60)

    # Determine date range
    if len(sys.argv) > 1:
        end_date = datetime.strptime(sys.argv[1], '%Y-%m-%d').date()
    else:
        end_date = datetime.utcnow().date()

    start_date = end_date - timedelta(days=6)
    start_str = start_date.strftime('%Y-%m-%d')
    end_str = end_date.strftime('%Y-%m-%d')
    print(f"Period: {start_str} â†’ {end_str}")

    # Load data
    print("[1/5] Loading predictions...")
    predictions = load_week_predictions(end_date, days=7)
    if predictions.empty:
        print("  âš  No prediction files found for the past 7 days.")
        print("  Generating empty review with no data.")

    print(f"  â†’ {len(predictions)} predictions loaded")
    days_with_data = predictions['date'].nunique() if not predictions.empty else 0
    print(f"  â†’ {days_with_data} days with data")

    print("[2/5] Loading results...")
    results = load_results(start_date, end_date)
    print(f"  â†’ {len(results)} game results loaded")

    print("[3/5] Evaluating picks...")
    evaluated = evaluate_picks(predictions, results)
    matched = len(evaluated)
    print(f"  â†’ {matched} predictions matched to results")

    if evaluated.empty and not predictions.empty:
        print("  âš  No results available yet (games not final or results not updated).")
        print("  Generating review with predictions summary only.")

    # Compute stats
    stats = {}
    for model in ['ml', 'rl', 'f5']:
        stats[model] = compute_tier_stats(evaluated, model)

    best_picks, worst_picks = find_notable_picks(evaluated)

    # Summary
    ml_all = stats.get('ml', {}).get('ALL', {})
    if ml_all:
        print(f"\n  === MONEYLINE SUMMARY ===")
        print(f"  Record: {ml_all['wins']}W-{ml_all['losses']}L")
        print(f"  Accuracy: {ml_all['accuracy']*100:.1f}%")
        print(f"  ROI: {ml_all['roi']:+.1f}%")

    # Generate outputs
    WEEKLY_DIR.mkdir(parents=True, exist_ok=True)

    print("[4/5] Generating weekly review (EN + JA)...")
    en_review = generate_english_review(stats, best_picks, worst_picks, evaluated, start_str, end_str, days_with_data)
    ja_review = generate_japanese_review(stats, best_picks, worst_picks, evaluated, start_str, end_str, days_with_data)

    en_path = WEEKLY_DIR / f"review_EN_{end_str}.md"
    ja_path = WEEKLY_DIR / f"review_JA_{end_str}.md"
    json_path = WEEKLY_DIR / f"review_data_{end_str}.json"

    en_path.write_text(en_review, encoding='utf-8')
    ja_path.write_text(ja_review, encoding='utf-8')
    print(f"  âœ“ {en_path.name}")
    print(f"  âœ“ {ja_path.name}")

    print("[5/5] Saving review data JSON...")
    review_data = {
        'generated': datetime.utcnow().isoformat(),
        'period': {'start': start_str, 'end': end_str},
        'days_with_data': days_with_data,
        'games_matched': matched,
        'stats': stats,
        'best_picks': best_picks,
        'worst_picks': worst_picks,
    }
    with open(json_path, 'w') as f:
        json.dump(review_data, f, indent=2, ensure_ascii=False)
    print(f"  âœ“ {json_path.name}")

    # Slack notification with full content
    print("[6/6] Sending Slack notifications...")
    notify_review(en_review, ja_review, stats, start_str, end_str)

    print(f"\nâœ… Weekly review generated â†’ {WEEKLY_DIR}/")


if __name__ == "__main__":
    main()
